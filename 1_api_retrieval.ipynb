{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gylam/siads696-sprsum2024-team05/blob/main/1_api_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9He9b-_kSr7"
      },
      "source": [
        "**Document retrieval**\n",
        "<br>\n",
        "Goal: Retrieve all English non-text documents containing themes - output table with document text and associated theme labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbRwy_EAsCki",
        "outputId": "3f182605-a32f-440a-ecf3-68320c37ca91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import time\n",
        "import os\n",
        "from bs4 import BeautifulSoup\n",
        "import warnings\n",
        "import typing\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIxzh0-I99iZ"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zHYhnyTsEOy"
      },
      "outputs": [],
      "source": [
        "## URLs for API calls\n",
        "\n",
        "# Uses profile for API calls, includes all following filters\n",
        "url_base = 'https://api.reliefweb.int/v1/reports?appname=apidoc&profile=full&filter[operator]=AND'\n",
        "# Sort by ascending document ID\n",
        "url_sort = '&sort[]=id:asc'\n",
        "# Filter for English language reports\n",
        "url_lang = '&filter[conditions][0][field]=language.id&filter[conditions][0][value]=267'\n",
        "# Exclude non-text formats (Infographic, Interactive, Map, Other)\n",
        "url_format1 = '&filter[conditions][1][field]=format.id&filter[conditions][1][value][]=12570&filter[conditions][1][value][]=12'\n",
        "url_format2 = '&filter[conditions][1][value][]=9&filter[conditions][1][value][]=38974&filter[conditions][1][operator]=OR&filter[conditions][1][negate]=true'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EKtc_5qQZChg"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "base_path = '/content/drive/MyDrive/_Course materials/S5M1-2 696 - Milestone II/Milestone 2 shared folder/data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfIq7qqwkMTu"
      },
      "outputs": [],
      "source": [
        "def extract_docs(doc_limit: int = 1000, tot_docs: int = None) -> int:\n",
        "  \"\"\" Call API to extract all English-language text documents with themes\n",
        "      Inputs:\n",
        "        - doc_limit: Number of documents to retrieve at a time (default and max is 1000)\n",
        "        - tot_docs: Total number of documents to retrieve (default is to retrieve all matching results)\n",
        "      Output:\n",
        "        - doc_df: Dataframe containing document text and themes\n",
        "  \"\"\"\n",
        "\n",
        "  # Set counter to track number of iterations until reach last set of documents\n",
        "  counter = 0\n",
        "  doc_df_created = False\n",
        "  report_num = 0\n",
        "\n",
        "  # Initializing df to store all documents from current API call\n",
        "  curr_df = pd.DataFrame(columns = ['report_id', 'theme_id', 'theme_name', 'text'])\n",
        "\n",
        "  # If no limit to tot_docs is specified, initially set to doc_limit\n",
        "  if tot_docs == None:\n",
        "    tot_docs = doc_limit\n",
        "    tot_docs_bool = False\n",
        "  else:\n",
        "    tot_docs_bool = True\n",
        "\n",
        "  # URL to indicate number of documents to return and how many to offset by\n",
        "  url_lim = f'&limit={doc_limit}&offset='\n",
        "\n",
        "  # Call API until all documents have been retrieved\n",
        "  while counter*doc_limit <= tot_docs:\n",
        "    print(f\"counter = {counter} with {counter*doc_limit} documents elapsed\")\n",
        "\n",
        "    # Make API request\n",
        "    if counter == 0:\n",
        "      full_url = url_base + url_sort + url_lang + url_lim + str(counter*doc_limit)\n",
        "    else:\n",
        "      full_url = url\n",
        "    response = requests.get(full_url, stream = True)\n",
        "\n",
        "    # Check that valid API call was made\n",
        "    if response.status_code == 200:\n",
        "      # If so, convert JSON output into dictionary\n",
        "      try:\n",
        "        rw_dict = response.json()\n",
        "      except Exception as e:\n",
        "        print(f'Error with retrieving API: {e}')\n",
        "        time.sleep(1)\n",
        "        continue\n",
        "\n",
        "    # For first iteration, update total number of documents to retrieve\n",
        "    if tot_docs_bool == False:\n",
        "      tot_docs = rw_dict[\"totalCount\"]\n",
        "\n",
        "    # Extract fields from all retrieved reports into a list\n",
        "    all_reports_data=[]\n",
        "    # For all API calls except for last call, retrieve doc_limit documents\n",
        "    if abs(tot_docs - counter*doc_limit) >= doc_limit:\n",
        "      for i in np.arange(int(doc_limit)):\n",
        "        all_reports_data.append(rw_dict['data'][i]['fields'])\n",
        "    # For last set of reports, retrieve all remaining reports\n",
        "    else:\n",
        "      for i in np.arange(int(abs(tot_docs - counter*doc_limit))):\n",
        "        all_reports_data.append(rw_dict['data'][i]['fields'])\n",
        "\n",
        "    # For each extracted report, attempt to extract theme and other relevant fields\n",
        "    for data_num, data in enumerate(all_reports_data):\n",
        "      try:\n",
        "        theme_id = []\n",
        "        theme_name = []\n",
        "\n",
        "        # Extract themes as a single list into 1 row\n",
        "        temp_theme_list = data['theme']\n",
        "        theme_id.append([theme['id'] for theme in temp_theme_list])\n",
        "        theme_name.append([theme['name'] for theme in temp_theme_list])\n",
        "\n",
        "        ## Create report text df\n",
        "        report_id = [data['id']]\n",
        "        # Extract body - clean up HTML tags\n",
        "        body_col = data['body']\n",
        "        soup_body = BeautifulSoup(body_col, 'lxml')\n",
        "        text = soup_body.get_text().replace('\\n', ' ')\n",
        "        # Extract title - clean up HTML tags\n",
        "        title_col = data['title']\n",
        "        soup_title = BeautifulSoup(title_col, 'lxml')\n",
        "        title = soup_title.get_text().replace('\\n', ' ')\n",
        "        # Combine title and text into a single column\n",
        "        combined_text = title + ' ' + text\n",
        "\n",
        "        # Store current URL, unless reach final set of documents\n",
        "        if abs(tot_docs - counter*doc_limit) >= doc_limit:\n",
        "          current_url = [list(rw_dict['links']['next'].values())[0]]\n",
        "        else:\n",
        "          current_url = ['']\n",
        "\n",
        "        # Store country information, document date, source name/id, format\n",
        "        latitude = [data['primary_country']['location']['lat']]\n",
        "        longitude = [data['primary_country']['location']['lon']]\n",
        "        country_iso3 = [data['primary_country']['iso3']]\n",
        "        country_name = [data['primary_country']['name']]\n",
        "        date_created = [data['date']['created']]\n",
        "        source_id = [str(data['source'][0]['id'])]\n",
        "        source_name = [data['source'][0]['name']]\n",
        "        format = [data['format'][0]['name']]\n",
        "\n",
        "        # Create dataframe from extracted fields\n",
        "        df_text = pd.DataFrame(list(zip(report_id, theme_id, theme_name, [title], [text], [combined_text],\n",
        "                                        [data['url']], latitude, longitude, country_iso3,\n",
        "                                        country_name, date_created, source_id, source_name, format )),\n",
        "                               columns = ['report_id', 'theme_id', 'theme_name', 'title', 'text', 'combined_text',\n",
        "                                          'url', 'latitude', 'longitude', 'country_iso3','country_name',\n",
        "                                          'date_created', 'source_id', 'source_name', 'format'])\n",
        "        # Add column with word count\n",
        "        df_text['word_count'] = df_text['combined_text'].apply(lambda x: len(str(x).split(' ')))\n",
        "\n",
        "        # Update curr_df to store all documents from current API call so far\n",
        "        curr_df = pd.concat([curr_df, df_text]) #df_merged\n",
        "\n",
        "        # Update url for next report API call (unless reached last set of documents)\n",
        "        if abs(tot_docs - counter*doc_limit) >= doc_limit:\n",
        "          url= list(rw_dict['links']['next'].values())[0]\n",
        "        else:\n",
        "          url = ['']\n",
        "\n",
        "      except Exception as e:\n",
        "        print(f'Error (in report extraction) {e}')\n",
        "        # Update url for next API call\n",
        "        url = list(rw_dict['links']['next'].values())[0]\n",
        "\n",
        "    # Increment counter for tracking number of reports added to dataframe\n",
        "    counter += 1\n",
        "\n",
        "    try:\n",
        "      # Drop rows that are non-text formats\n",
        "      curr_df = curr_df[(curr_df['format'] != 'Map') & (curr_df['format'] != 'Interactive') & \\\n",
        "                        (curr_df['format'] != 'Infographic') & (curr_df['format'] != 'Other')]\n",
        "      curr_df = curr_df.dropna()\n",
        "      curr_df = curr_df.reset_index().drop('index', axis = 1)\n",
        "\n",
        "      # When reach at least 1000 documents in curr_df, save to pickle and reset\n",
        "      curr_report_num = len(curr_df['report_id'].unique())\n",
        "      if curr_report_num >= 1000:\n",
        "        # Add current number of reports to report_num\n",
        "        report_num += curr_report_num\n",
        "\n",
        "        # Save current df to pickle\n",
        "        curr_df.to_pickle(base_path + 'gl_files_v2/gl_pickle_' + str(curr_report_num) + 'docs_' + str(counter*doc_limit) + '.pickle')\n",
        "\n",
        "        # Reset curr_df\n",
        "        curr_df = pd.DataFrame(columns = ['report_id', 'theme_id', 'theme_name', 'text'])\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f'Error (in appending curr_df) {e}')\n",
        "      continue\n",
        "\n",
        "  return report_num\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCZ9agVUfP1F",
        "outputId": "dbd19ad7-066b-4915-c3e5-c218329b9c3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial args: doc_limit = 1000, tot_docs = None\n",
            "counter = 0 with 0 documents elapsed\n",
            "counter = 1 with 1000 documents elapsed\n",
            "counter = 2 with 2000 documents elapsed\n",
            "counter = 3 with 3000 documents elapsed\n",
            "counter = 4 with 4000 documents elapsed\n",
            "counter = 5 with 5000 documents elapsed\n",
            "counter = 6 with 6000 documents elapsed\n",
            "counter = 7 with 7000 documents elapsed\n",
            "counter = 8 with 8000 documents elapsed\n",
            "counter = 9 with 9000 documents elapsed\n",
            "counter = 10 with 10000 documents elapsed\n",
            "counter = 11 with 11000 documents elapsed\n",
            "counter = 12 with 12000 documents elapsed\n",
            "counter = 13 with 13000 documents elapsed\n",
            "counter = 14 with 14000 documents elapsed\n",
            "counter = 15 with 15000 documents elapsed\n",
            "counter = 16 with 16000 documents elapsed\n",
            "counter = 17 with 17000 documents elapsed\n",
            "counter = 18 with 18000 documents elapsed\n",
            "counter = 19 with 19000 documents elapsed\n",
            "counter = 20 with 20000 documents elapsed\n",
            "counter = 21 with 21000 documents elapsed\n",
            "counter = 22 with 22000 documents elapsed\n",
            "counter = 23 with 23000 documents elapsed\n",
            "counter = 23 with 23000 documents elapsed\n",
            "counter = 24 with 24000 documents elapsed\n",
            "counter = 24 with 24000 documents elapsed\n",
            "counter = 24 with 24000 documents elapsed\n",
            "counter = 25 with 25000 documents elapsed\n",
            "counter = 25 with 25000 documents elapsed\n",
            "counter = 26 with 26000 documents elapsed\n",
            "counter = 27 with 27000 documents elapsed\n",
            "counter = 28 with 28000 documents elapsed\n",
            "counter = 29 with 29000 documents elapsed\n",
            "counter = 30 with 30000 documents elapsed\n",
            "counter = 31 with 31000 documents elapsed\n",
            "counter = 32 with 32000 documents elapsed\n",
            "counter = 33 with 33000 documents elapsed\n",
            "counter = 34 with 34000 documents elapsed\n",
            "counter = 34 with 34000 documents elapsed\n",
            "counter = 35 with 35000 documents elapsed\n",
            "counter = 36 with 36000 documents elapsed\n",
            "counter = 37 with 37000 documents elapsed\n",
            "counter = 38 with 38000 documents elapsed\n",
            "counter = 39 with 39000 documents elapsed\n",
            "counter = 40 with 40000 documents elapsed\n",
            "counter = 41 with 41000 documents elapsed\n",
            "counter = 42 with 42000 documents elapsed\n",
            "counter = 43 with 43000 documents elapsed\n",
            "counter = 44 with 44000 documents elapsed\n",
            "counter = 44 with 44000 documents elapsed\n",
            "counter = 45 with 45000 documents elapsed\n",
            "counter = 46 with 46000 documents elapsed\n",
            "counter = 47 with 47000 documents elapsed\n",
            "counter = 48 with 48000 documents elapsed\n",
            "curr_df.shape after drop: (903, 16)\n",
            "counter = 49 with 49000 documents elapsed\n",
            "curr_df.shape after drop: (951, 16)\n",
            "counter = 50 with 50000 documents elapsed\n",
            "curr_df.shape after drop: (1003, 16)\n",
            "# unique reports in curr_df: 1003 >= 1000\n",
            "total number of reports: 1003\n",
            "counter = 51 with 51000 documents elapsed\n",
            "counter = 52 with 52000 documents elapsed\n",
            "counter = 53 with 53000 documents elapsed\n",
            "counter = 53 with 53000 documents elapsed\n",
            "counter = 54 with 54000 documents elapsed\n",
            "counter = 55 with 55000 documents elapsed\n",
            "counter = 56 with 56000 documents elapsed\n",
            "counter = 57 with 57000 documents elapsed\n",
            "counter = 58 with 58000 documents elapsed\n",
            "counter = 58 with 58000 documents elapsed\n",
            "counter = 58 with 58000 documents elapsed\n",
            "counter = 58 with 58000 documents elapsed\n",
            "counter = 59 with 59000 documents elapsed\n",
            "counter = 60 with 60000 documents elapsed\n",
            "counter = 61 with 61000 documents elapsed\n",
            "counter = 61 with 61000 documents elapsed\n",
            "counter = 62 with 62000 documents elapsed\n",
            "counter = 63 with 63000 documents elapsed\n",
            "counter = 64 with 64000 documents elapsed\n",
            "counter = 64 with 64000 documents elapsed\n",
            "curr_df.shape after drop: (986, 16)\n",
            "counter = 65 with 65000 documents elapsed\n",
            "curr_df.shape after drop: (1077, 16)\n",
            "# unique reports in curr_df: 1077 >= 1000\n",
            "total number of reports: 2080\n",
            "counter = 66 with 66000 documents elapsed\n",
            "counter = 66 with 66000 documents elapsed\n",
            "counter = 66 with 66000 documents elapsed\n",
            "counter = 66 with 66000 documents elapsed\n",
            "counter = 67 with 67000 documents elapsed\n",
            "counter = 68 with 68000 documents elapsed\n",
            "counter = 68 with 68000 documents elapsed\n",
            "counter = 68 with 68000 documents elapsed\n",
            "counter = 68 with 68000 documents elapsed\n",
            "counter = 68 with 68000 documents elapsed\n",
            "counter = 69 with 69000 documents elapsed\n",
            "counter = 69 with 69000 documents elapsed\n",
            "counter = 69 with 69000 documents elapsed\n",
            "counter = 69 with 69000 documents elapsed\n",
            "counter = 70 with 70000 documents elapsed\n",
            "counter = 70 with 70000 documents elapsed\n",
            "counter = 70 with 70000 documents elapsed\n",
            "counter = 70 with 70000 documents elapsed\n",
            "counter = 70 with 70000 documents elapsed\n",
            "counter = 70 with 70000 documents elapsed\n",
            "counter = 70 with 70000 documents elapsed\n",
            "counter = 71 with 71000 documents elapsed\n",
            "counter = 72 with 72000 documents elapsed\n",
            "counter = 72 with 72000 documents elapsed\n",
            "counter = 73 with 73000 documents elapsed\n",
            "counter = 74 with 74000 documents elapsed\n",
            "counter = 74 with 74000 documents elapsed\n",
            "counter = 75 with 75000 documents elapsed\n",
            "counter = 76 with 76000 documents elapsed\n",
            "counter = 76 with 76000 documents elapsed\n",
            "counter = 76 with 76000 documents elapsed\n",
            "counter = 76 with 76000 documents elapsed\n",
            "counter = 76 with 76000 documents elapsed\n",
            "counter = 77 with 77000 documents elapsed\n",
            "counter = 77 with 77000 documents elapsed\n",
            "counter = 78 with 78000 documents elapsed\n",
            "counter = 79 with 79000 documents elapsed\n",
            "counter = 79 with 79000 documents elapsed\n",
            "counter = 80 with 80000 documents elapsed\n",
            "counter = 80 with 80000 documents elapsed\n",
            "counter = 80 with 80000 documents elapsed\n",
            "curr_df.shape after drop: (902, 16)\n",
            "counter = 81 with 81000 documents elapsed\n",
            "curr_df.shape after drop: (948, 16)\n",
            "counter = 82 with 82000 documents elapsed\n",
            "counter = 82 with 82000 documents elapsed\n",
            "curr_df.shape after drop: (987, 16)\n",
            "counter = 83 with 83000 documents elapsed\n",
            "counter = 83 with 83000 documents elapsed\n",
            "counter = 83 with 83000 documents elapsed\n",
            "counter = 83 with 83000 documents elapsed\n",
            "counter = 83 with 83000 documents elapsed\n",
            "curr_df.shape after drop: (1037, 16)\n",
            "# unique reports in curr_df: 1037 >= 1000\n",
            "total number of reports: 3117\n",
            "counter = 84 with 84000 documents elapsed\n",
            "counter = 85 with 85000 documents elapsed\n",
            "counter = 85 with 85000 documents elapsed\n",
            "counter = 85 with 85000 documents elapsed\n",
            "counter = 85 with 85000 documents elapsed\n",
            "counter = 86 with 86000 documents elapsed\n",
            "counter = 86 with 86000 documents elapsed\n",
            "counter = 86 with 86000 documents elapsed\n",
            "counter = 86 with 86000 documents elapsed\n",
            "counter = 86 with 86000 documents elapsed\n",
            "counter = 86 with 86000 documents elapsed\n",
            "counter = 86 with 86000 documents elapsed\n",
            "counter = 87 with 87000 documents elapsed\n",
            "counter = 88 with 88000 documents elapsed\n",
            "counter = 88 with 88000 documents elapsed\n",
            "counter = 89 with 89000 documents elapsed\n",
            "curr_df.shape after drop: (1003, 16)\n",
            "# unique reports in curr_df: 1003 >= 1000\n",
            "total number of reports: 4120\n",
            "counter = 90 with 90000 documents elapsed\n",
            "counter = 90 with 90000 documents elapsed\n",
            "counter = 90 with 90000 documents elapsed\n",
            "counter = 90 with 90000 documents elapsed\n",
            "counter = 91 with 91000 documents elapsed\n",
            "counter = 91 with 91000 documents elapsed\n",
            "counter = 92 with 92000 documents elapsed\n",
            "curr_df.shape after drop: (1225, 16)\n",
            "# unique reports in curr_df: 1225 >= 1000\n",
            "total number of reports: 5345\n",
            "counter = 93 with 93000 documents elapsed\n",
            "counter = 94 with 94000 documents elapsed\n",
            "counter = 94 with 94000 documents elapsed\n",
            "counter = 94 with 94000 documents elapsed\n",
            "counter = 94 with 94000 documents elapsed\n",
            "counter = 94 with 94000 documents elapsed\n",
            "curr_df.shape after drop: (1047, 16)\n",
            "# unique reports in curr_df: 1047 >= 1000\n",
            "total number of reports: 6392\n",
            "counter = 95 with 95000 documents elapsed\n",
            "counter = 95 with 95000 documents elapsed\n",
            "counter = 95 with 95000 documents elapsed\n",
            "counter = 96 with 96000 documents elapsed\n",
            "counter = 96 with 96000 documents elapsed\n",
            "curr_df.shape after drop: (988, 16)\n",
            "counter = 97 with 97000 documents elapsed\n",
            "counter = 97 with 97000 documents elapsed\n",
            "curr_df.shape after drop: (1493, 16)\n",
            "# unique reports in curr_df: 1493 >= 1000\n",
            "total number of reports: 7885\n",
            "counter = 98 with 98000 documents elapsed\n",
            "counter = 99 with 99000 documents elapsed\n",
            "counter = 99 with 99000 documents elapsed\n",
            "counter = 99 with 99000 documents elapsed\n",
            "curr_df.shape after drop: (943, 16)\n",
            "counter = 100 with 100000 documents elapsed\n",
            "counter = 100 with 100000 documents elapsed\n",
            "counter = 100 with 100000 documents elapsed\n",
            "counter = 100 with 100000 documents elapsed\n",
            "counter = 100 with 100000 documents elapsed\n",
            "counter = 100 with 100000 documents elapsed\n",
            "counter = 100 with 100000 documents elapsed\n",
            "curr_df.shape after drop: (1397, 16)\n",
            "# unique reports in curr_df: 1397 >= 1000\n",
            "total number of reports: 9282\n",
            "counter = 101 with 101000 documents elapsed\n",
            "counter = 102 with 102000 documents elapsed\n",
            "counter = 102 with 102000 documents elapsed\n",
            "counter = 103 with 103000 documents elapsed\n",
            "counter = 103 with 103000 documents elapsed\n",
            "curr_df.shape after drop: (1293, 16)\n",
            "# unique reports in curr_df: 1293 >= 1000\n",
            "total number of reports: 10575\n",
            "counter = 104 with 104000 documents elapsed\n",
            "counter = 104 with 104000 documents elapsed\n",
            "counter = 104 with 104000 documents elapsed\n",
            "counter = 104 with 104000 documents elapsed\n",
            "counter = 104 with 104000 documents elapsed\n",
            "counter = 104 with 104000 documents elapsed\n",
            "counter = 104 with 104000 documents elapsed\n",
            "counter = 104 with 104000 documents elapsed\n",
            "counter = 104 with 104000 documents elapsed\n",
            "counter = 104 with 104000 documents elapsed\n",
            "counter = 104 with 104000 documents elapsed\n",
            "counter = 104 with 104000 documents elapsed\n",
            "counter = 105 with 105000 documents elapsed\n",
            "curr_df.shape after drop: (928, 16)\n",
            "counter = 106 with 106000 documents elapsed\n",
            "counter = 106 with 106000 documents elapsed\n",
            "counter = 106 with 106000 documents elapsed\n",
            "curr_df.shape after drop: (1373, 16)\n",
            "# unique reports in curr_df: 1373 >= 1000\n",
            "total number of reports: 11948\n",
            "counter = 107 with 107000 documents elapsed\n",
            "counter = 107 with 107000 documents elapsed\n",
            "counter = 107 with 107000 documents elapsed\n",
            "counter = 108 with 108000 documents elapsed\n",
            "counter = 109 with 109000 documents elapsed\n",
            "curr_df.shape after drop: (1353, 16)\n",
            "# unique reports in curr_df: 1353 >= 1000\n",
            "total number of reports: 13301\n",
            "counter = 110 with 110000 documents elapsed\n",
            "counter = 110 with 110000 documents elapsed\n",
            "counter = 111 with 111000 documents elapsed\n",
            "counter = 111 with 111000 documents elapsed\n",
            "curr_df.shape after drop: (989, 16)\n",
            "counter = 112 with 112000 documents elapsed\n",
            "counter = 112 with 112000 documents elapsed\n",
            "counter = 112 with 112000 documents elapsed\n",
            "counter = 112 with 112000 documents elapsed\n",
            "counter = 112 with 112000 documents elapsed\n",
            "curr_df.shape after drop: (1552, 16)\n",
            "# unique reports in curr_df: 1552 >= 1000\n",
            "total number of reports: 14853\n",
            "counter = 113 with 113000 documents elapsed\n",
            "counter = 113 with 113000 documents elapsed\n",
            "counter = 114 with 114000 documents elapsed\n",
            "curr_df.shape after drop: (919, 16)\n",
            "counter = 115 with 115000 documents elapsed\n",
            "curr_df.shape after drop: (1387, 16)\n",
            "# unique reports in curr_df: 1387 >= 1000\n",
            "total number of reports: 16240\n",
            "counter = 116 with 116000 documents elapsed\n",
            "counter = 116 with 116000 documents elapsed\n",
            "counter = 117 with 117000 documents elapsed\n",
            "counter = 118 with 118000 documents elapsed\n",
            "curr_df.shape after drop: (1284, 16)\n",
            "# unique reports in curr_df: 1284 >= 1000\n",
            "total number of reports: 17524\n",
            "counter = 119 with 119000 documents elapsed\n",
            "counter = 120 with 120000 documents elapsed\n",
            "curr_df.shape after drop: (920, 16)\n",
            "counter = 121 with 121000 documents elapsed\n",
            "counter = 121 with 121000 documents elapsed\n",
            "counter = 121 with 121000 documents elapsed\n",
            "curr_df.shape after drop: (1374, 16)\n",
            "# unique reports in curr_df: 1374 >= 1000\n",
            "total number of reports: 18898\n",
            "counter = 122 with 122000 documents elapsed\n",
            "counter = 123 with 123000 documents elapsed\n",
            "curr_df.shape after drop: (914, 16)\n",
            "counter = 124 with 124000 documents elapsed\n",
            "counter = 124 with 124000 documents elapsed\n",
            "curr_df.shape after drop: (1349, 16)\n",
            "# unique reports in curr_df: 1349 >= 1000\n",
            "total number of reports: 20247\n",
            "counter = 125 with 125000 documents elapsed\n",
            "counter = 126 with 126000 documents elapsed\n",
            "counter = 127 with 127000 documents elapsed\n",
            "curr_df.shape after drop: (1197, 16)\n",
            "# unique reports in curr_df: 1197 >= 1000\n",
            "total number of reports: 21444\n",
            "counter = 128 with 128000 documents elapsed\n",
            "counter = 129 with 129000 documents elapsed\n",
            "counter = 130 with 130000 documents elapsed\n",
            "curr_df.shape after drop: (1209, 16)\n",
            "# unique reports in curr_df: 1209 >= 1000\n",
            "total number of reports: 22653\n",
            "counter = 131 with 131000 documents elapsed\n",
            "counter = 132 with 132000 documents elapsed\n",
            "counter = 132 with 132000 documents elapsed\n",
            "counter = 132 with 132000 documents elapsed\n",
            "counter = 132 with 132000 documents elapsed\n",
            "counter = 133 with 133000 documents elapsed\n",
            "curr_df.shape after drop: (1049, 16)\n",
            "# unique reports in curr_df: 1049 >= 1000\n",
            "total number of reports: 23702\n",
            "counter = 134 with 134000 documents elapsed\n",
            "counter = 135 with 135000 documents elapsed\n",
            "counter = 136 with 136000 documents elapsed\n",
            "curr_df.shape after drop: (984, 16)\n",
            "counter = 137 with 137000 documents elapsed\n",
            "curr_df.shape after drop: (1403, 16)\n",
            "# unique reports in curr_df: 1403 >= 1000\n",
            "total number of reports: 25105\n",
            "counter = 138 with 138000 documents elapsed\n",
            "counter = 139 with 139000 documents elapsed\n",
            "counter = 140 with 140000 documents elapsed\n",
            "curr_df.shape after drop: (1082, 16)\n",
            "# unique reports in curr_df: 1082 >= 1000\n",
            "total number of reports: 26187\n",
            "counter = 141 with 141000 documents elapsed\n",
            "counter = 141 with 141000 documents elapsed\n",
            "counter = 142 with 142000 documents elapsed\n",
            "counter = 143 with 143000 documents elapsed\n",
            "curr_df.shape after drop: (1234, 16)\n",
            "# unique reports in curr_df: 1234 >= 1000\n",
            "total number of reports: 27421\n",
            "counter = 144 with 144000 documents elapsed\n",
            "counter = 145 with 145000 documents elapsed\n",
            "counter = 146 with 146000 documents elapsed\n",
            "curr_df.shape after drop: (1265, 16)\n",
            "# unique reports in curr_df: 1265 >= 1000\n",
            "total number of reports: 28686\n",
            "counter = 147 with 147000 documents elapsed\n",
            "counter = 148 with 148000 documents elapsed\n",
            "counter = 148 with 148000 documents elapsed\n",
            "counter = 149 with 149000 documents elapsed\n",
            "curr_df.shape after drop: (1244, 16)\n",
            "# unique reports in curr_df: 1244 >= 1000\n",
            "total number of reports: 29930\n",
            "counter = 150 with 150000 documents elapsed\n",
            "counter = 151 with 151000 documents elapsed\n",
            "counter = 152 with 152000 documents elapsed\n",
            "curr_df.shape after drop: (1067, 16)\n",
            "# unique reports in curr_df: 1067 >= 1000\n",
            "total number of reports: 30997\n",
            "counter = 153 with 153000 documents elapsed\n",
            "counter = 154 with 154000 documents elapsed\n",
            "counter = 154 with 154000 documents elapsed\n",
            "counter = 155 with 155000 documents elapsed\n",
            "curr_df.shape after drop: (1058, 16)\n",
            "# unique reports in curr_df: 1058 >= 1000\n",
            "total number of reports: 32055\n",
            "counter = 156 with 156000 documents elapsed\n",
            "counter = 156 with 156000 documents elapsed\n",
            "counter = 157 with 157000 documents elapsed\n",
            "counter = 158 with 158000 documents elapsed\n",
            "curr_df.shape after drop: (924, 16)\n",
            "counter = 159 with 159000 documents elapsed\n",
            "curr_df.shape after drop: (1264, 16)\n",
            "# unique reports in curr_df: 1264 >= 1000\n",
            "total number of reports: 33319\n",
            "counter = 160 with 160000 documents elapsed\n",
            "counter = 161 with 161000 documents elapsed\n",
            "counter = 162 with 162000 documents elapsed\n",
            "curr_df.shape after drop: (935, 16)\n",
            "counter = 163 with 163000 documents elapsed\n",
            "curr_df.shape after drop: (1284, 16)\n",
            "# unique reports in curr_df: 1284 >= 1000\n",
            "total number of reports: 34603\n",
            "counter = 164 with 164000 documents elapsed\n",
            "counter = 164 with 164000 documents elapsed\n",
            "counter = 165 with 165000 documents elapsed\n",
            "counter = 166 with 166000 documents elapsed\n",
            "counter = 167 with 167000 documents elapsed\n",
            "curr_df.shape after drop: (1161, 16)\n",
            "# unique reports in curr_df: 1161 >= 1000\n",
            "total number of reports: 35764\n",
            "counter = 168 with 168000 documents elapsed\n",
            "counter = 169 with 169000 documents elapsed\n",
            "counter = 170 with 170000 documents elapsed\n",
            "curr_df.shape after drop: (1223, 16)\n",
            "# unique reports in curr_df: 1223 >= 1000\n",
            "total number of reports: 36987\n",
            "counter = 171 with 171000 documents elapsed\n",
            "counter = 172 with 172000 documents elapsed\n",
            "counter = 173 with 173000 documents elapsed\n",
            "curr_df.shape after drop: (1184, 16)\n",
            "# unique reports in curr_df: 1184 >= 1000\n",
            "total number of reports: 38171\n",
            "counter = 174 with 174000 documents elapsed\n",
            "counter = 175 with 175000 documents elapsed\n",
            "counter = 175 with 175000 documents elapsed\n",
            "counter = 176 with 176000 documents elapsed\n",
            "curr_df.shape after drop: (1160, 16)\n",
            "# unique reports in curr_df: 1160 >= 1000\n",
            "total number of reports: 39331\n",
            "counter = 177 with 177000 documents elapsed\n",
            "counter = 178 with 178000 documents elapsed\n",
            "counter = 179 with 179000 documents elapsed\n",
            "counter = 179 with 179000 documents elapsed\n",
            "curr_df.shape after drop: (1343, 16)\n",
            "# unique reports in curr_df: 1343 >= 1000\n",
            "total number of reports: 40674\n",
            "counter = 180 with 180000 documents elapsed\n",
            "counter = 181 with 181000 documents elapsed\n",
            "counter = 182 with 182000 documents elapsed\n",
            "curr_df.shape after drop: (1205, 16)\n",
            "# unique reports in curr_df: 1205 >= 1000\n",
            "total number of reports: 41879\n",
            "counter = 183 with 183000 documents elapsed\n",
            "counter = 183 with 183000 documents elapsed\n",
            "counter = 184 with 184000 documents elapsed\n",
            "curr_df.shape after drop: (902, 16)\n",
            "counter = 185 with 185000 documents elapsed\n",
            "curr_df.shape after drop: (1372, 16)\n",
            "# unique reports in curr_df: 1372 >= 1000\n",
            "total number of reports: 43251\n",
            "counter = 186 with 186000 documents elapsed\n",
            "counter = 187 with 187000 documents elapsed\n",
            "counter = 188 with 188000 documents elapsed\n",
            "curr_df.shape after drop: (1402, 16)\n",
            "# unique reports in curr_df: 1402 >= 1000\n",
            "total number of reports: 44653\n",
            "counter = 189 with 189000 documents elapsed\n",
            "counter = 190 with 190000 documents elapsed\n",
            "counter = 191 with 191000 documents elapsed\n",
            "curr_df.shape after drop: (1288, 16)\n",
            "# unique reports in curr_df: 1288 >= 1000\n",
            "total number of reports: 45941\n",
            "counter = 192 with 192000 documents elapsed\n",
            "counter = 192 with 192000 documents elapsed\n",
            "counter = 193 with 193000 documents elapsed\n",
            "curr_df.shape after drop: (924, 16)\n",
            "counter = 194 with 194000 documents elapsed\n",
            "counter = 194 with 194000 documents elapsed\n",
            "counter = 194 with 194000 documents elapsed\n",
            "curr_df.shape after drop: (1368, 16)\n",
            "# unique reports in curr_df: 1368 >= 1000\n",
            "total number of reports: 47309\n",
            "counter = 195 with 195000 documents elapsed\n",
            "counter = 196 with 196000 documents elapsed\n",
            "counter = 196 with 196000 documents elapsed\n",
            "curr_df.shape after drop: (944, 16)\n",
            "counter = 197 with 197000 documents elapsed\n",
            "curr_df.shape after drop: (1359, 16)\n",
            "# unique reports in curr_df: 1359 >= 1000\n",
            "total number of reports: 48668\n",
            "counter = 198 with 198000 documents elapsed\n",
            "counter = 199 with 199000 documents elapsed\n",
            "counter = 200 with 200000 documents elapsed\n",
            "curr_df.shape after drop: (1192, 16)\n",
            "# unique reports in curr_df: 1192 >= 1000\n",
            "total number of reports: 49860\n",
            "counter = 201 with 201000 documents elapsed\n",
            "counter = 202 with 202000 documents elapsed\n",
            "counter = 203 with 203000 documents elapsed\n",
            "curr_df.shape after drop: (1185, 16)\n",
            "# unique reports in curr_df: 1185 >= 1000\n",
            "total number of reports: 51045\n",
            "counter = 204 with 204000 documents elapsed\n",
            "counter = 204 with 204000 documents elapsed\n",
            "counter = 204 with 204000 documents elapsed\n",
            "counter = 205 with 205000 documents elapsed\n",
            "counter = 206 with 206000 documents elapsed\n",
            "curr_df.shape after drop: (1112, 16)\n",
            "# unique reports in curr_df: 1112 >= 1000\n",
            "total number of reports: 52157\n",
            "counter = 207 with 207000 documents elapsed\n",
            "counter = 208 with 208000 documents elapsed\n",
            "counter = 209 with 209000 documents elapsed\n",
            "curr_df.shape after drop: (1200, 16)\n",
            "# unique reports in curr_df: 1200 >= 1000\n",
            "total number of reports: 53357\n",
            "counter = 210 with 210000 documents elapsed\n",
            "counter = 211 with 211000 documents elapsed\n",
            "counter = 212 with 212000 documents elapsed\n",
            "curr_df.shape after drop: (1194, 16)\n",
            "# unique reports in curr_df: 1194 >= 1000\n",
            "total number of reports: 54551\n",
            "counter = 213 with 213000 documents elapsed\n",
            "counter = 214 with 214000 documents elapsed\n",
            "counter = 215 with 215000 documents elapsed\n",
            "curr_df.shape after drop: (1063, 16)\n",
            "# unique reports in curr_df: 1063 >= 1000\n",
            "total number of reports: 55614\n",
            "counter = 216 with 216000 documents elapsed\n",
            "counter = 217 with 217000 documents elapsed\n",
            "counter = 218 with 218000 documents elapsed\n",
            "curr_df.shape after drop: (1097, 16)\n",
            "# unique reports in curr_df: 1097 >= 1000\n",
            "total number of reports: 56711\n",
            "counter = 219 with 219000 documents elapsed\n",
            "counter = 220 with 220000 documents elapsed\n",
            "counter = 221 with 221000 documents elapsed\n",
            "curr_df.shape after drop: (1151, 16)\n",
            "# unique reports in curr_df: 1151 >= 1000\n",
            "total number of reports: 57862\n",
            "counter = 222 with 222000 documents elapsed\n",
            "counter = 223 with 223000 documents elapsed\n",
            "counter = 224 with 224000 documents elapsed\n",
            "curr_df.shape after drop: (1190, 16)\n",
            "# unique reports in curr_df: 1190 >= 1000\n",
            "total number of reports: 59052\n",
            "counter = 225 with 225000 documents elapsed\n",
            "counter = 226 with 226000 documents elapsed\n",
            "counter = 227 with 227000 documents elapsed\n",
            "curr_df.shape after drop: (1136, 16)\n",
            "# unique reports in curr_df: 1136 >= 1000\n",
            "total number of reports: 60188\n",
            "counter = 228 with 228000 documents elapsed\n",
            "counter = 229 with 229000 documents elapsed\n",
            "counter = 230 with 230000 documents elapsed\n",
            "curr_df.shape after drop: (1109, 16)\n",
            "# unique reports in curr_df: 1109 >= 1000\n",
            "total number of reports: 61297\n",
            "counter = 231 with 231000 documents elapsed\n",
            "counter = 232 with 232000 documents elapsed\n",
            "counter = 233 with 233000 documents elapsed\n",
            "curr_df.shape after drop: (1179, 16)\n",
            "# unique reports in curr_df: 1179 >= 1000\n",
            "total number of reports: 62476\n",
            "counter = 234 with 234000 documents elapsed\n",
            "counter = 235 with 235000 documents elapsed\n",
            "counter = 236 with 236000 documents elapsed\n",
            "curr_df.shape after drop: (1205, 16)\n",
            "# unique reports in curr_df: 1205 >= 1000\n",
            "total number of reports: 63681\n",
            "counter = 237 with 237000 documents elapsed\n",
            "counter = 238 with 238000 documents elapsed\n",
            "counter = 239 with 239000 documents elapsed\n",
            "curr_df.shape after drop: (1303, 16)\n",
            "# unique reports in curr_df: 1303 >= 1000\n",
            "total number of reports: 64984\n",
            "counter = 240 with 240000 documents elapsed\n",
            "counter = 240 with 240000 documents elapsed\n",
            "counter = 241 with 241000 documents elapsed\n",
            "counter = 241 with 241000 documents elapsed\n",
            "counter = 241 with 241000 documents elapsed\n",
            "counter = 242 with 242000 documents elapsed\n",
            "counter = 242 with 242000 documents elapsed\n",
            "curr_df.shape after drop: (1257, 16)\n",
            "# unique reports in curr_df: 1257 >= 1000\n",
            "total number of reports: 66241\n",
            "counter = 243 with 243000 documents elapsed\n",
            "counter = 243 with 243000 documents elapsed\n",
            "counter = 244 with 244000 documents elapsed\n",
            "counter = 245 with 245000 documents elapsed\n",
            "curr_df.shape after drop: (1304, 16)\n",
            "# unique reports in curr_df: 1304 >= 1000\n",
            "total number of reports: 67545\n",
            "counter = 246 with 246000 documents elapsed\n",
            "counter = 247 with 247000 documents elapsed\n",
            "counter = 248 with 248000 documents elapsed\n",
            "curr_df.shape after drop: (1256, 16)\n",
            "# unique reports in curr_df: 1256 >= 1000\n",
            "total number of reports: 68801\n",
            "counter = 249 with 249000 documents elapsed\n",
            "counter = 250 with 250000 documents elapsed\n",
            "counter = 251 with 251000 documents elapsed\n",
            "curr_df.shape after drop: (1230, 16)\n",
            "# unique reports in curr_df: 1230 >= 1000\n",
            "total number of reports: 70031\n",
            "counter = 252 with 252000 documents elapsed\n",
            "counter = 253 with 253000 documents elapsed\n",
            "counter = 253 with 253000 documents elapsed\n",
            "counter = 254 with 254000 documents elapsed\n",
            "curr_df.shape after drop: (1296, 16)\n",
            "# unique reports in curr_df: 1296 >= 1000\n",
            "total number of reports: 71327\n",
            "counter = 255 with 255000 documents elapsed\n",
            "counter = 255 with 255000 documents elapsed\n",
            "counter = 256 with 256000 documents elapsed\n",
            "counter = 256 with 256000 documents elapsed\n",
            "counter = 257 with 257000 documents elapsed\n",
            "curr_df.shape after drop: (1205, 16)\n",
            "# unique reports in curr_df: 1205 >= 1000\n",
            "total number of reports: 72532\n",
            "counter = 258 with 258000 documents elapsed\n",
            "counter = 259 with 259000 documents elapsed\n",
            "counter = 260 with 260000 documents elapsed\n",
            "curr_df.shape after drop: (1256, 16)\n",
            "# unique reports in curr_df: 1256 >= 1000\n",
            "total number of reports: 73788\n",
            "counter = 261 with 261000 documents elapsed\n",
            "counter = 262 with 262000 documents elapsed\n",
            "counter = 263 with 263000 documents elapsed\n",
            "curr_df.shape after drop: (1303, 16)\n",
            "# unique reports in curr_df: 1303 >= 1000\n",
            "total number of reports: 75091\n",
            "counter = 264 with 264000 documents elapsed\n",
            "counter = 265 with 265000 documents elapsed\n",
            "curr_df.shape after drop: (926, 16)\n",
            "counter = 266 with 266000 documents elapsed\n",
            "curr_df.shape after drop: (1356, 16)\n",
            "# unique reports in curr_df: 1356 >= 1000\n",
            "total number of reports: 76447\n",
            "counter = 267 with 267000 documents elapsed\n",
            "counter = 268 with 268000 documents elapsed\n",
            "curr_df.shape after drop: (956, 16)\n",
            "counter = 269 with 269000 documents elapsed\n",
            "curr_df.shape after drop: (1435, 16)\n",
            "# unique reports in curr_df: 1435 >= 1000\n",
            "total number of reports: 77882\n",
            "counter = 270 with 270000 documents elapsed\n",
            "counter = 271 with 271000 documents elapsed\n",
            "curr_df.shape after drop: (901, 16)\n",
            "counter = 272 with 272000 documents elapsed\n",
            "curr_df.shape after drop: (1371, 16)\n",
            "# unique reports in curr_df: 1371 >= 1000\n",
            "total number of reports: 79253\n",
            "counter = 273 with 273000 documents elapsed\n",
            "counter = 274 with 274000 documents elapsed\n",
            "counter = 275 with 275000 documents elapsed\n",
            "curr_df.shape after drop: (1314, 16)\n",
            "# unique reports in curr_df: 1314 >= 1000\n",
            "total number of reports: 80567\n",
            "counter = 276 with 276000 documents elapsed\n",
            "counter = 277 with 277000 documents elapsed\n",
            "curr_df.shape after drop: (915, 16)\n",
            "counter = 278 with 278000 documents elapsed\n",
            "curr_df.shape after drop: (1430, 16)\n",
            "# unique reports in curr_df: 1430 >= 1000\n",
            "total number of reports: 81997\n",
            "counter = 279 with 279000 documents elapsed\n",
            "counter = 280 with 280000 documents elapsed\n",
            "curr_df.shape after drop: (983, 16)\n",
            "counter = 281 with 281000 documents elapsed\n",
            "curr_df.shape after drop: (1486, 16)\n",
            "# unique reports in curr_df: 1486 >= 1000\n",
            "total number of reports: 83483\n",
            "counter = 282 with 282000 documents elapsed\n",
            "counter = 283 with 283000 documents elapsed\n",
            "curr_df.shape after drop: (996, 16)\n",
            "counter = 284 with 284000 documents elapsed\n",
            "curr_df.shape after drop: (1460, 16)\n",
            "# unique reports in curr_df: 1460 >= 1000\n",
            "total number of reports: 84943\n",
            "counter = 285 with 285000 documents elapsed\n",
            "counter = 286 with 286000 documents elapsed\n",
            "curr_df.shape after drop: (1071, 16)\n",
            "# unique reports in curr_df: 1071 >= 1000\n",
            "total number of reports: 86014\n",
            "counter = 287 with 287000 documents elapsed\n",
            "counter = 288 with 288000 documents elapsed\n",
            "curr_df.shape after drop: (1023, 16)\n",
            "# unique reports in curr_df: 1023 >= 1000\n",
            "total number of reports: 87037\n",
            "counter = 289 with 289000 documents elapsed\n",
            "counter = 290 with 290000 documents elapsed\n",
            "curr_df.shape after drop: (1088, 16)\n",
            "# unique reports in curr_df: 1088 >= 1000\n",
            "total number of reports: 88125\n",
            "counter = 291 with 291000 documents elapsed\n",
            "counter = 292 with 292000 documents elapsed\n",
            "curr_df.shape after drop: (1103, 16)\n",
            "# unique reports in curr_df: 1103 >= 1000\n",
            "total number of reports: 89228\n",
            "counter = 293 with 293000 documents elapsed\n",
            "counter = 294 with 294000 documents elapsed\n",
            "curr_df.shape after drop: (1144, 16)\n",
            "# unique reports in curr_df: 1144 >= 1000\n",
            "total number of reports: 90372\n",
            "counter = 295 with 295000 documents elapsed\n",
            "counter = 296 with 296000 documents elapsed\n",
            "curr_df.shape after drop: (1141, 16)\n",
            "# unique reports in curr_df: 1141 >= 1000\n",
            "total number of reports: 91513\n",
            "counter = 297 with 297000 documents elapsed\n",
            "counter = 298 with 298000 documents elapsed\n",
            "curr_df.shape after drop: (1128, 16)\n",
            "# unique reports in curr_df: 1128 >= 1000\n",
            "total number of reports: 92641\n",
            "counter = 299 with 299000 documents elapsed\n",
            "counter = 300 with 300000 documents elapsed\n",
            "curr_df.shape after drop: (1213, 16)\n",
            "# unique reports in curr_df: 1213 >= 1000\n",
            "total number of reports: 93854\n",
            "counter = 301 with 301000 documents elapsed\n",
            "counter = 302 with 302000 documents elapsed\n",
            "curr_df.shape after drop: (1444, 16)\n",
            "# unique reports in curr_df: 1444 >= 1000\n",
            "total number of reports: 95298\n",
            "counter = 303 with 303000 documents elapsed\n",
            "counter = 304 with 304000 documents elapsed\n",
            "curr_df.shape after drop: (1462, 16)\n",
            "# unique reports in curr_df: 1462 >= 1000\n",
            "total number of reports: 96760\n",
            "counter = 305 with 305000 documents elapsed\n",
            "counter = 306 with 306000 documents elapsed\n",
            "counter = 307 with 307000 documents elapsed\n",
            "counter = 307 with 307000 documents elapsed\n",
            "counter = 307 with 307000 documents elapsed\n",
            "counter = 308 with 308000 documents elapsed\n",
            "curr_df.shape after drop: (1660, 16)\n",
            "# unique reports in curr_df: 1660 >= 1000\n",
            "total number of reports: 98420\n",
            "counter = 309 with 309000 documents elapsed\n",
            "counter = 310 with 310000 documents elapsed\n",
            "curr_df.shape after drop: (1298, 16)\n",
            "# unique reports in curr_df: 1298 >= 1000\n",
            "total number of reports: 99718\n",
            "counter = 311 with 311000 documents elapsed\n",
            "curr_df.shape after drop: (914, 16)\n",
            "counter = 312 with 312000 documents elapsed\n",
            "curr_df.shape after drop: (1811, 16)\n",
            "# unique reports in curr_df: 1811 >= 1000\n",
            "total number of reports: 101529\n",
            "counter = 313 with 313000 documents elapsed\n",
            "counter = 314 with 314000 documents elapsed\n",
            "curr_df.shape after drop: (1688, 16)\n",
            "# unique reports in curr_df: 1688 >= 1000\n",
            "total number of reports: 103217\n",
            "counter = 315 with 315000 documents elapsed\n",
            "counter = 316 with 316000 documents elapsed\n",
            "curr_df.shape after drop: (1296, 16)\n",
            "# unique reports in curr_df: 1296 >= 1000\n",
            "total number of reports: 104513\n",
            "counter = 317 with 317000 documents elapsed\n",
            "counter = 318 with 318000 documents elapsed\n",
            "curr_df.shape after drop: (1517, 16)\n",
            "# unique reports in curr_df: 1517 >= 1000\n",
            "total number of reports: 106030\n",
            "counter = 319 with 319000 documents elapsed\n",
            "counter = 320 with 320000 documents elapsed\n",
            "counter = 321 with 321000 documents elapsed\n",
            "curr_df.shape after drop: (1256, 16)\n",
            "# unique reports in curr_df: 1256 >= 1000\n",
            "total number of reports: 107286\n",
            "counter = 322 with 322000 documents elapsed\n",
            "counter = 323 with 323000 documents elapsed\n",
            "counter = 324 with 324000 documents elapsed\n",
            "curr_df.shape after drop: (1041, 16)\n",
            "# unique reports in curr_df: 1041 >= 1000\n",
            "total number of reports: 108327\n",
            "counter = 325 with 325000 documents elapsed\n",
            "counter = 326 with 326000 documents elapsed\n",
            "counter = 326 with 326000 documents elapsed\n",
            "counter = 326 with 326000 documents elapsed\n",
            "counter = 326 with 326000 documents elapsed\n",
            "curr_df.shape after drop: (999, 16)\n",
            "counter = 327 with 327000 documents elapsed\n",
            "curr_df.shape after drop: (1738, 16)\n",
            "# unique reports in curr_df: 1738 >= 1000\n",
            "total number of reports: 110065\n",
            "counter = 328 with 328000 documents elapsed\n",
            "counter = 329 with 329000 documents elapsed\n",
            "curr_df.shape after drop: (1465, 16)\n",
            "# unique reports in curr_df: 1465 >= 1000\n",
            "total number of reports: 111530\n",
            "counter = 330 with 330000 documents elapsed\n",
            "counter = 331 with 331000 documents elapsed\n",
            "curr_df.shape after drop: (1482, 16)\n",
            "# unique reports in curr_df: 1482 >= 1000\n",
            "total number of reports: 113012\n",
            "counter = 332 with 332000 documents elapsed\n",
            "counter = 333 with 333000 documents elapsed\n",
            "curr_df.shape after drop: (1518, 16)\n",
            "# unique reports in curr_df: 1518 >= 1000\n",
            "total number of reports: 114530\n",
            "counter = 334 with 334000 documents elapsed\n",
            "counter = 335 with 335000 documents elapsed\n",
            "curr_df.shape after drop: (1470, 16)\n",
            "# unique reports in curr_df: 1470 >= 1000\n",
            "total number of reports: 116000\n",
            "counter = 336 with 336000 documents elapsed\n",
            "counter = 337 with 337000 documents elapsed\n",
            "curr_df.shape after drop: (1508, 16)\n",
            "# unique reports in curr_df: 1508 >= 1000\n",
            "total number of reports: 117508\n",
            "counter = 338 with 338000 documents elapsed\n",
            "counter = 339 with 339000 documents elapsed\n",
            "curr_df.shape after drop: (1473, 16)\n",
            "# unique reports in curr_df: 1473 >= 1000\n",
            "total number of reports: 118981\n",
            "counter = 340 with 340000 documents elapsed\n",
            "counter = 341 with 341000 documents elapsed\n",
            "curr_df.shape after drop: (1545, 16)\n",
            "# unique reports in curr_df: 1545 >= 1000\n",
            "total number of reports: 120526\n",
            "counter = 342 with 342000 documents elapsed\n",
            "counter = 343 with 343000 documents elapsed\n",
            "curr_df.shape after drop: (1541, 16)\n",
            "# unique reports in curr_df: 1541 >= 1000\n",
            "total number of reports: 122067\n",
            "counter = 344 with 344000 documents elapsed\n",
            "counter = 345 with 345000 documents elapsed\n",
            "curr_df.shape after drop: (1549, 16)\n",
            "# unique reports in curr_df: 1549 >= 1000\n",
            "total number of reports: 123616\n",
            "counter = 346 with 346000 documents elapsed\n",
            "counter = 347 with 347000 documents elapsed\n",
            "curr_df.shape after drop: (1571, 16)\n",
            "# unique reports in curr_df: 1571 >= 1000\n",
            "total number of reports: 125187\n",
            "counter = 348 with 348000 documents elapsed\n",
            "counter = 349 with 349000 documents elapsed\n",
            "curr_df.shape after drop: (1512, 16)\n",
            "# unique reports in curr_df: 1512 >= 1000\n",
            "total number of reports: 126699\n",
            "counter = 350 with 350000 documents elapsed\n",
            "counter = 351 with 351000 documents elapsed\n",
            "curr_df.shape after drop: (1514, 16)\n",
            "# unique reports in curr_df: 1514 >= 1000\n",
            "total number of reports: 128213\n",
            "counter = 352 with 352000 documents elapsed\n",
            "counter = 353 with 353000 documents elapsed\n",
            "curr_df.shape after drop: (1480, 16)\n",
            "# unique reports in curr_df: 1480 >= 1000\n",
            "total number of reports: 129693\n",
            "counter = 354 with 354000 documents elapsed\n",
            "counter = 355 with 355000 documents elapsed\n",
            "curr_df.shape after drop: (1455, 16)\n",
            "# unique reports in curr_df: 1455 >= 1000\n",
            "total number of reports: 131148\n",
            "counter = 356 with 356000 documents elapsed\n",
            "counter = 357 with 357000 documents elapsed\n",
            "curr_df.shape after drop: (1385, 16)\n",
            "# unique reports in curr_df: 1385 >= 1000\n",
            "total number of reports: 132533\n",
            "counter = 358 with 358000 documents elapsed\n",
            "counter = 359 with 359000 documents elapsed\n",
            "curr_df.shape after drop: (1447, 16)\n",
            "# unique reports in curr_df: 1447 >= 1000\n",
            "total number of reports: 133980\n",
            "counter = 360 with 360000 documents elapsed\n",
            "counter = 361 with 361000 documents elapsed\n",
            "curr_df.shape after drop: (1461, 16)\n",
            "# unique reports in curr_df: 1461 >= 1000\n",
            "total number of reports: 135441\n",
            "counter = 362 with 362000 documents elapsed\n",
            "counter = 363 with 363000 documents elapsed\n",
            "curr_df.shape after drop: (1531, 16)\n",
            "# unique reports in curr_df: 1531 >= 1000\n",
            "total number of reports: 136972\n",
            "counter = 364 with 364000 documents elapsed\n",
            "counter = 365 with 365000 documents elapsed\n",
            "curr_df.shape after drop: (1512, 16)\n",
            "# unique reports in curr_df: 1512 >= 1000\n",
            "total number of reports: 138484\n",
            "counter = 366 with 366000 documents elapsed\n",
            "counter = 367 with 367000 documents elapsed\n",
            "curr_df.shape after drop: (1493, 16)\n",
            "# unique reports in curr_df: 1493 >= 1000\n",
            "total number of reports: 139977\n",
            "counter = 368 with 368000 documents elapsed\n",
            "counter = 369 with 369000 documents elapsed\n",
            "curr_df.shape after drop: (1447, 16)\n",
            "# unique reports in curr_df: 1447 >= 1000\n",
            "total number of reports: 141424\n",
            "counter = 370 with 370000 documents elapsed\n",
            "counter = 371 with 371000 documents elapsed\n",
            "curr_df.shape after drop: (1491, 16)\n",
            "# unique reports in curr_df: 1491 >= 1000\n",
            "total number of reports: 142915\n",
            "counter = 372 with 372000 documents elapsed\n",
            "counter = 373 with 373000 documents elapsed\n",
            "curr_df.shape after drop: (1516, 16)\n",
            "# unique reports in curr_df: 1516 >= 1000\n",
            "total number of reports: 144431\n",
            "counter = 374 with 374000 documents elapsed\n",
            "counter = 375 with 375000 documents elapsed\n",
            "curr_df.shape after drop: (1332, 16)\n",
            "# unique reports in curr_df: 1332 >= 1000\n",
            "total number of reports: 145763\n",
            "counter = 376 with 376000 documents elapsed\n",
            "counter = 377 with 377000 documents elapsed\n",
            "curr_df.shape after drop: (1534, 16)\n",
            "# unique reports in curr_df: 1534 >= 1000\n",
            "total number of reports: 147297\n",
            "counter = 378 with 378000 documents elapsed\n",
            "counter = 379 with 379000 documents elapsed\n",
            "curr_df.shape after drop: (1550, 16)\n",
            "# unique reports in curr_df: 1550 >= 1000\n",
            "total number of reports: 148847\n",
            "counter = 380 with 380000 documents elapsed\n",
            "counter = 381 with 381000 documents elapsed\n",
            "curr_df.shape after drop: (1459, 16)\n",
            "# unique reports in curr_df: 1459 >= 1000\n",
            "total number of reports: 150306\n",
            "counter = 382 with 382000 documents elapsed\n",
            "counter = 383 with 383000 documents elapsed\n",
            "curr_df.shape after drop: (1418, 16)\n",
            "# unique reports in curr_df: 1418 >= 1000\n",
            "total number of reports: 151724\n",
            "counter = 384 with 384000 documents elapsed\n",
            "counter = 385 with 385000 documents elapsed\n",
            "curr_df.shape after drop: (1406, 16)\n",
            "# unique reports in curr_df: 1406 >= 1000\n",
            "total number of reports: 153130\n",
            "counter = 386 with 386000 documents elapsed\n",
            "counter = 387 with 387000 documents elapsed\n",
            "curr_df.shape after drop: (1364, 16)\n",
            "# unique reports in curr_df: 1364 >= 1000\n",
            "total number of reports: 154494\n",
            "counter = 388 with 388000 documents elapsed\n",
            "counter = 389 with 389000 documents elapsed\n",
            "curr_df.shape after drop: (1376, 16)\n",
            "# unique reports in curr_df: 1376 >= 1000\n",
            "total number of reports: 155870\n",
            "counter = 390 with 390000 documents elapsed\n",
            "counter = 391 with 391000 documents elapsed\n",
            "curr_df.shape after drop: (1355, 16)\n",
            "# unique reports in curr_df: 1355 >= 1000\n",
            "total number of reports: 157225\n",
            "counter = 392 with 392000 documents elapsed\n",
            "counter = 393 with 393000 documents elapsed\n",
            "curr_df.shape after drop: (1347, 16)\n",
            "# unique reports in curr_df: 1347 >= 1000\n",
            "total number of reports: 158572\n",
            "counter = 394 with 394000 documents elapsed\n",
            "counter = 395 with 395000 documents elapsed\n",
            "curr_df.shape after drop: (1270, 16)\n",
            "# unique reports in curr_df: 1270 >= 1000\n",
            "total number of reports: 159842\n",
            "counter = 396 with 396000 documents elapsed\n",
            "counter = 397 with 397000 documents elapsed\n",
            "curr_df.shape after drop: (1452, 16)\n",
            "# unique reports in curr_df: 1452 >= 1000\n",
            "total number of reports: 161294\n",
            "counter = 398 with 398000 documents elapsed\n",
            "counter = 399 with 399000 documents elapsed\n",
            "curr_df.shape after drop: (1432, 16)\n",
            "# unique reports in curr_df: 1432 >= 1000\n",
            "total number of reports: 162726\n",
            "counter = 400 with 400000 documents elapsed\n",
            "counter = 401 with 401000 documents elapsed\n",
            "curr_df.shape after drop: (1351, 16)\n",
            "# unique reports in curr_df: 1351 >= 1000\n",
            "total number of reports: 164077\n",
            "counter = 402 with 402000 documents elapsed\n",
            "counter = 402 with 402000 documents elapsed\n",
            "counter = 403 with 403000 documents elapsed\n",
            "curr_df.shape after drop: (1323, 16)\n",
            "# unique reports in curr_df: 1323 >= 1000\n",
            "total number of reports: 165400\n",
            "counter = 404 with 404000 documents elapsed\n",
            "counter = 405 with 405000 documents elapsed\n",
            "curr_df.shape after drop: (1368, 16)\n",
            "# unique reports in curr_df: 1368 >= 1000\n",
            "total number of reports: 166768\n",
            "counter = 406 with 406000 documents elapsed\n",
            "counter = 407 with 407000 documents elapsed\n",
            "curr_df.shape after drop: (1372, 16)\n",
            "# unique reports in curr_df: 1372 >= 1000\n",
            "total number of reports: 168140\n",
            "counter = 408 with 408000 documents elapsed\n",
            "counter = 409 with 409000 documents elapsed\n",
            "curr_df.shape after drop: (1424, 16)\n",
            "# unique reports in curr_df: 1424 >= 1000\n",
            "total number of reports: 169564\n",
            "counter = 410 with 410000 documents elapsed\n",
            "counter = 411 with 411000 documents elapsed\n",
            "curr_df.shape after drop: (1397, 16)\n",
            "# unique reports in curr_df: 1397 >= 1000\n",
            "total number of reports: 170961\n",
            "counter = 412 with 412000 documents elapsed\n",
            "counter = 413 with 413000 documents elapsed\n",
            "curr_df.shape after drop: (1495, 16)\n",
            "# unique reports in curr_df: 1495 >= 1000\n",
            "total number of reports: 172456\n",
            "counter = 414 with 414000 documents elapsed\n",
            "counter = 415 with 415000 documents elapsed\n",
            "curr_df.shape after drop: (1397, 16)\n",
            "# unique reports in curr_df: 1397 >= 1000\n",
            "total number of reports: 173853\n",
            "counter = 416 with 416000 documents elapsed\n",
            "counter = 417 with 417000 documents elapsed\n",
            "curr_df.shape after drop: (1363, 16)\n",
            "# unique reports in curr_df: 1363 >= 1000\n",
            "total number of reports: 175216\n",
            "counter = 418 with 418000 documents elapsed\n",
            "counter = 419 with 419000 documents elapsed\n",
            "curr_df.shape after drop: (1268, 16)\n",
            "# unique reports in curr_df: 1268 >= 1000\n",
            "total number of reports: 176484\n",
            "counter = 420 with 420000 documents elapsed\n",
            "counter = 421 with 421000 documents elapsed\n",
            "curr_df.shape after drop: (1337, 16)\n",
            "# unique reports in curr_df: 1337 >= 1000\n",
            "total number of reports: 177821\n",
            "counter = 422 with 422000 documents elapsed\n",
            "counter = 423 with 423000 documents elapsed\n",
            "curr_df.shape after drop: (1287, 16)\n",
            "# unique reports in curr_df: 1287 >= 1000\n",
            "total number of reports: 179108\n",
            "counter = 424 with 424000 documents elapsed\n",
            "counter = 425 with 425000 documents elapsed\n",
            "curr_df.shape after drop: (1353, 16)\n",
            "# unique reports in curr_df: 1353 >= 1000\n",
            "total number of reports: 180461\n",
            "counter = 426 with 426000 documents elapsed\n",
            "counter = 427 with 427000 documents elapsed\n",
            "curr_df.shape after drop: (1362, 16)\n",
            "# unique reports in curr_df: 1362 >= 1000\n",
            "total number of reports: 181823\n",
            "counter = 428 with 428000 documents elapsed\n",
            "counter = 429 with 429000 documents elapsed\n",
            "curr_df.shape after drop: (1392, 16)\n",
            "# unique reports in curr_df: 1392 >= 1000\n",
            "total number of reports: 183215\n",
            "counter = 430 with 430000 documents elapsed\n",
            "counter = 431 with 431000 documents elapsed\n",
            "curr_df.shape after drop: (1460, 16)\n",
            "# unique reports in curr_df: 1460 >= 1000\n",
            "total number of reports: 184675\n",
            "counter = 432 with 432000 documents elapsed\n",
            "counter = 433 with 433000 documents elapsed\n",
            "curr_df.shape after drop: (1467, 16)\n",
            "# unique reports in curr_df: 1467 >= 1000\n",
            "total number of reports: 186142\n",
            "counter = 434 with 434000 documents elapsed\n",
            "counter = 435 with 435000 documents elapsed\n",
            "curr_df.shape after drop: (1332, 16)\n",
            "# unique reports in curr_df: 1332 >= 1000\n",
            "total number of reports: 187474\n",
            "counter = 436 with 436000 documents elapsed\n",
            "counter = 437 with 437000 documents elapsed\n",
            "curr_df.shape after drop: (1301, 16)\n",
            "# unique reports in curr_df: 1301 >= 1000\n",
            "total number of reports: 188775\n",
            "counter = 438 with 438000 documents elapsed\n",
            "counter = 439 with 439000 documents elapsed\n",
            "curr_df.shape after drop: (1333, 16)\n",
            "# unique reports in curr_df: 1333 >= 1000\n",
            "total number of reports: 190108\n",
            "counter = 440 with 440000 documents elapsed\n",
            "counter = 441 with 441000 documents elapsed\n",
            "curr_df.shape after drop: (1372, 16)\n",
            "# unique reports in curr_df: 1372 >= 1000\n",
            "total number of reports: 191480\n",
            "counter = 442 with 442000 documents elapsed\n",
            "counter = 443 with 443000 documents elapsed\n",
            "curr_df.shape after drop: (1402, 16)\n",
            "# unique reports in curr_df: 1402 >= 1000\n",
            "total number of reports: 192882\n",
            "counter = 444 with 444000 documents elapsed\n",
            "counter = 445 with 445000 documents elapsed\n",
            "curr_df.shape after drop: (1346, 16)\n",
            "# unique reports in curr_df: 1346 >= 1000\n",
            "total number of reports: 194228\n",
            "counter = 446 with 446000 documents elapsed\n",
            "counter = 447 with 447000 documents elapsed\n",
            "curr_df.shape after drop: (1204, 16)\n",
            "# unique reports in curr_df: 1204 >= 1000\n",
            "total number of reports: 195432\n",
            "counter = 448 with 448000 documents elapsed\n",
            "counter = 449 with 449000 documents elapsed\n",
            "curr_df.shape after drop: (1188, 16)\n",
            "# unique reports in curr_df: 1188 >= 1000\n",
            "total number of reports: 196620\n",
            "counter = 450 with 450000 documents elapsed\n",
            "counter = 451 with 451000 documents elapsed\n",
            "curr_df.shape after drop: (1271, 16)\n",
            "# unique reports in curr_df: 1271 >= 1000\n",
            "total number of reports: 197891\n",
            "counter = 452 with 452000 documents elapsed\n",
            "counter = 453 with 453000 documents elapsed\n",
            "curr_df.shape after drop: (1314, 16)\n",
            "# unique reports in curr_df: 1314 >= 1000\n",
            "total number of reports: 199205\n",
            "counter = 454 with 454000 documents elapsed\n",
            "counter = 455 with 455000 documents elapsed\n",
            "curr_df.shape after drop: (1199, 16)\n",
            "# unique reports in curr_df: 1199 >= 1000\n",
            "total number of reports: 200404\n",
            "counter = 456 with 456000 documents elapsed\n",
            "counter = 457 with 457000 documents elapsed\n",
            "curr_df.shape after drop: (1242, 16)\n",
            "# unique reports in curr_df: 1242 >= 1000\n",
            "total number of reports: 201646\n",
            "counter = 458 with 458000 documents elapsed\n",
            "counter = 459 with 459000 documents elapsed\n",
            "curr_df.shape after drop: (1285, 16)\n",
            "# unique reports in curr_df: 1285 >= 1000\n",
            "total number of reports: 202931\n",
            "counter = 460 with 460000 documents elapsed\n",
            "counter = 461 with 461000 documents elapsed\n",
            "curr_df.shape after drop: (1379, 16)\n",
            "# unique reports in curr_df: 1379 >= 1000\n",
            "total number of reports: 204310\n",
            "counter = 462 with 462000 documents elapsed\n",
            "counter = 463 with 463000 documents elapsed\n",
            "curr_df.shape after drop: (1313, 16)\n",
            "# unique reports in curr_df: 1313 >= 1000\n",
            "total number of reports: 205623\n",
            "counter = 464 with 464000 documents elapsed\n",
            "counter = 465 with 465000 documents elapsed\n",
            "curr_df.shape after drop: (1203, 16)\n",
            "# unique reports in curr_df: 1203 >= 1000\n",
            "total number of reports: 206826\n",
            "counter = 466 with 466000 documents elapsed\n",
            "counter = 467 with 467000 documents elapsed\n",
            "curr_df.shape after drop: (1269, 16)\n",
            "# unique reports in curr_df: 1269 >= 1000\n",
            "total number of reports: 208095\n",
            "counter = 468 with 468000 documents elapsed\n",
            "counter = 469 with 469000 documents elapsed\n",
            "curr_df.shape after drop: (1293, 16)\n",
            "# unique reports in curr_df: 1293 >= 1000\n",
            "total number of reports: 209388\n",
            "counter = 470 with 470000 documents elapsed\n",
            "counter = 471 with 471000 documents elapsed\n",
            "curr_df.shape after drop: (1288, 16)\n",
            "# unique reports in curr_df: 1288 >= 1000\n",
            "total number of reports: 210676\n",
            "counter = 472 with 472000 documents elapsed\n",
            "counter = 473 with 473000 documents elapsed\n",
            "curr_df.shape after drop: (1246, 16)\n",
            "# unique reports in curr_df: 1246 >= 1000\n",
            "total number of reports: 211922\n",
            "counter = 474 with 474000 documents elapsed\n",
            "counter = 475 with 475000 documents elapsed\n",
            "curr_df.shape after drop: (1190, 16)\n",
            "# unique reports in curr_df: 1190 >= 1000\n",
            "total number of reports: 213112\n",
            "counter = 476 with 476000 documents elapsed\n",
            "counter = 477 with 477000 documents elapsed\n",
            "curr_df.shape after drop: (1234, 16)\n",
            "# unique reports in curr_df: 1234 >= 1000\n",
            "total number of reports: 214346\n",
            "counter = 478 with 478000 documents elapsed\n",
            "counter = 479 with 479000 documents elapsed\n",
            "curr_df.shape after drop: (1160, 16)\n",
            "# unique reports in curr_df: 1160 >= 1000\n",
            "total number of reports: 215506\n",
            "counter = 480 with 480000 documents elapsed\n",
            "counter = 481 with 481000 documents elapsed\n",
            "curr_df.shape after drop: (1311, 16)\n",
            "# unique reports in curr_df: 1311 >= 1000\n",
            "total number of reports: 216817\n",
            "counter = 482 with 482000 documents elapsed\n",
            "counter = 483 with 483000 documents elapsed\n",
            "curr_df.shape after drop: (1187, 16)\n",
            "# unique reports in curr_df: 1187 >= 1000\n",
            "total number of reports: 218004\n",
            "counter = 484 with 484000 documents elapsed\n",
            "counter = 485 with 485000 documents elapsed\n",
            "curr_df.shape after drop: (1259, 16)\n",
            "# unique reports in curr_df: 1259 >= 1000\n",
            "total number of reports: 219263\n",
            "counter = 486 with 486000 documents elapsed\n",
            "counter = 487 with 487000 documents elapsed\n",
            "curr_df.shape after drop: (1231, 16)\n",
            "# unique reports in curr_df: 1231 >= 1000\n",
            "total number of reports: 220494\n",
            "counter = 488 with 488000 documents elapsed\n",
            "counter = 489 with 489000 documents elapsed\n",
            "curr_df.shape after drop: (1210, 16)\n",
            "# unique reports in curr_df: 1210 >= 1000\n",
            "total number of reports: 221704\n",
            "counter = 490 with 490000 documents elapsed\n",
            "counter = 491 with 491000 documents elapsed\n",
            "curr_df.shape after drop: (1230, 16)\n",
            "# unique reports in curr_df: 1230 >= 1000\n",
            "total number of reports: 222934\n",
            "counter = 492 with 492000 documents elapsed\n",
            "counter = 493 with 493000 documents elapsed\n",
            "curr_df.shape after drop: (1186, 16)\n",
            "# unique reports in curr_df: 1186 >= 1000\n",
            "total number of reports: 224120\n",
            "counter = 494 with 494000 documents elapsed\n",
            "counter = 495 with 495000 documents elapsed\n",
            "curr_df.shape after drop: (1196, 16)\n",
            "# unique reports in curr_df: 1196 >= 1000\n",
            "total number of reports: 225316\n",
            "counter = 496 with 496000 documents elapsed\n",
            "counter = 497 with 497000 documents elapsed\n",
            "curr_df.shape after drop: (1284, 16)\n",
            "# unique reports in curr_df: 1284 >= 1000\n",
            "total number of reports: 226600\n",
            "counter = 498 with 498000 documents elapsed\n",
            "counter = 499 with 499000 documents elapsed\n",
            "curr_df.shape after drop: (1188, 16)\n",
            "# unique reports in curr_df: 1188 >= 1000\n",
            "total number of reports: 227788\n",
            "counter = 500 with 500000 documents elapsed\n",
            "counter = 501 with 501000 documents elapsed\n",
            "curr_df.shape after drop: (1308, 16)\n",
            "# unique reports in curr_df: 1308 >= 1000\n",
            "total number of reports: 229096\n",
            "counter = 502 with 502000 documents elapsed\n",
            "counter = 503 with 503000 documents elapsed\n",
            "curr_df.shape after drop: (1262, 16)\n",
            "# unique reports in curr_df: 1262 >= 1000\n",
            "total number of reports: 230358\n",
            "counter = 504 with 504000 documents elapsed\n",
            "counter = 505 with 505000 documents elapsed\n",
            "curr_df.shape after drop: (1239, 16)\n",
            "# unique reports in curr_df: 1239 >= 1000\n",
            "total number of reports: 231597\n",
            "counter = 506 with 506000 documents elapsed\n",
            "counter = 507 with 507000 documents elapsed\n",
            "curr_df.shape after drop: (1308, 16)\n",
            "# unique reports in curr_df: 1308 >= 1000\n",
            "total number of reports: 232905\n",
            "counter = 508 with 508000 documents elapsed\n",
            "counter = 509 with 509000 documents elapsed\n",
            "curr_df.shape after drop: (1262, 16)\n",
            "# unique reports in curr_df: 1262 >= 1000\n",
            "total number of reports: 234167\n",
            "counter = 510 with 510000 documents elapsed\n",
            "counter = 511 with 511000 documents elapsed\n",
            "curr_df.shape after drop: (1242, 16)\n",
            "# unique reports in curr_df: 1242 >= 1000\n",
            "total number of reports: 235409\n",
            "counter = 512 with 512000 documents elapsed\n",
            "counter = 513 with 513000 documents elapsed\n",
            "curr_df.shape after drop: (1135, 16)\n",
            "# unique reports in curr_df: 1135 >= 1000\n",
            "total number of reports: 236544\n",
            "counter = 514 with 514000 documents elapsed\n",
            "counter = 515 with 515000 documents elapsed\n",
            "curr_df.shape after drop: (1281, 16)\n",
            "# unique reports in curr_df: 1281 >= 1000\n",
            "total number of reports: 237825\n",
            "counter = 516 with 516000 documents elapsed\n",
            "counter = 517 with 517000 documents elapsed\n",
            "curr_df.shape after drop: (1355, 16)\n",
            "# unique reports in curr_df: 1355 >= 1000\n",
            "total number of reports: 239180\n",
            "counter = 518 with 518000 documents elapsed\n",
            "counter = 519 with 519000 documents elapsed\n",
            "curr_df.shape after drop: (1315, 16)\n",
            "# unique reports in curr_df: 1315 >= 1000\n",
            "total number of reports: 240495\n",
            "counter = 520 with 520000 documents elapsed\n",
            "counter = 521 with 521000 documents elapsed\n",
            "curr_df.shape after drop: (1190, 16)\n",
            "# unique reports in curr_df: 1190 >= 1000\n",
            "total number of reports: 241685\n",
            "counter = 522 with 522000 documents elapsed\n",
            "counter = 523 with 523000 documents elapsed\n",
            "curr_df.shape after drop: (1298, 16)\n",
            "# unique reports in curr_df: 1298 >= 1000\n",
            "total number of reports: 242983\n",
            "counter = 524 with 524000 documents elapsed\n",
            "counter = 525 with 525000 documents elapsed\n",
            "curr_df.shape after drop: (1343, 16)\n",
            "# unique reports in curr_df: 1343 >= 1000\n",
            "total number of reports: 244326\n",
            "counter = 526 with 526000 documents elapsed\n",
            "counter = 527 with 527000 documents elapsed\n",
            "curr_df.shape after drop: (1285, 16)\n",
            "# unique reports in curr_df: 1285 >= 1000\n",
            "total number of reports: 245611\n",
            "counter = 528 with 528000 documents elapsed\n",
            "counter = 529 with 529000 documents elapsed\n",
            "curr_df.shape after drop: (1181, 16)\n",
            "# unique reports in curr_df: 1181 >= 1000\n",
            "total number of reports: 246792\n",
            "counter = 530 with 530000 documents elapsed\n",
            "counter = 531 with 531000 documents elapsed\n",
            "curr_df.shape after drop: (1351, 16)\n",
            "# unique reports in curr_df: 1351 >= 1000\n",
            "total number of reports: 248143\n",
            "counter = 532 with 532000 documents elapsed\n",
            "counter = 533 with 533000 documents elapsed\n",
            "curr_df.shape after drop: (1362, 16)\n",
            "# unique reports in curr_df: 1362 >= 1000\n",
            "total number of reports: 249505\n",
            "counter = 534 with 534000 documents elapsed\n",
            "counter = 535 with 535000 documents elapsed\n",
            "curr_df.shape after drop: (1312, 16)\n",
            "# unique reports in curr_df: 1312 >= 1000\n",
            "total number of reports: 250817\n",
            "counter = 536 with 536000 documents elapsed\n",
            "counter = 537 with 537000 documents elapsed\n",
            "curr_df.shape after drop: (1332, 16)\n",
            "# unique reports in curr_df: 1332 >= 1000\n",
            "total number of reports: 252149\n",
            "counter = 538 with 538000 documents elapsed\n",
            "counter = 539 with 539000 documents elapsed\n",
            "curr_df.shape after drop: (1325, 16)\n",
            "# unique reports in curr_df: 1325 >= 1000\n",
            "total number of reports: 253474\n",
            "counter = 540 with 540000 documents elapsed\n",
            "counter = 541 with 541000 documents elapsed\n",
            "curr_df.shape after drop: (1322, 16)\n",
            "# unique reports in curr_df: 1322 >= 1000\n",
            "total number of reports: 254796\n",
            "counter = 542 with 542000 documents elapsed\n",
            "counter = 543 with 543000 documents elapsed\n",
            "curr_df.shape after drop: (1274, 16)\n",
            "# unique reports in curr_df: 1274 >= 1000\n",
            "total number of reports: 256070\n",
            "counter = 544 with 544000 documents elapsed\n",
            "counter = 545 with 545000 documents elapsed\n",
            "curr_df.shape after drop: (1333, 16)\n",
            "# unique reports in curr_df: 1333 >= 1000\n",
            "total number of reports: 257403\n",
            "counter = 546 with 546000 documents elapsed\n",
            "counter = 547 with 547000 documents elapsed\n",
            "curr_df.shape after drop: (1393, 16)\n",
            "# unique reports in curr_df: 1393 >= 1000\n",
            "total number of reports: 258796\n",
            "counter = 548 with 548000 documents elapsed\n",
            "counter = 549 with 549000 documents elapsed\n",
            "curr_df.shape after drop: (1387, 16)\n",
            "# unique reports in curr_df: 1387 >= 1000\n",
            "total number of reports: 260183\n",
            "counter = 550 with 550000 documents elapsed\n",
            "counter = 551 with 551000 documents elapsed\n",
            "curr_df.shape after drop: (1327, 16)\n",
            "# unique reports in curr_df: 1327 >= 1000\n",
            "total number of reports: 261510\n",
            "counter = 552 with 552000 documents elapsed\n",
            "counter = 553 with 553000 documents elapsed\n",
            "curr_df.shape after drop: (1284, 16)\n",
            "# unique reports in curr_df: 1284 >= 1000\n",
            "total number of reports: 262794\n",
            "counter = 554 with 554000 documents elapsed\n",
            "counter = 555 with 555000 documents elapsed\n",
            "curr_df.shape after drop: (1185, 16)\n",
            "# unique reports in curr_df: 1185 >= 1000\n",
            "total number of reports: 263979\n",
            "counter = 556 with 556000 documents elapsed\n",
            "counter = 557 with 557000 documents elapsed\n",
            "curr_df.shape after drop: (1207, 16)\n",
            "# unique reports in curr_df: 1207 >= 1000\n",
            "total number of reports: 265186\n",
            "counter = 558 with 558000 documents elapsed\n",
            "counter = 559 with 559000 documents elapsed\n",
            "curr_df.shape after drop: (1261, 16)\n",
            "# unique reports in curr_df: 1261 >= 1000\n",
            "total number of reports: 266447\n",
            "counter = 560 with 560000 documents elapsed\n",
            "counter = 561 with 561000 documents elapsed\n",
            "curr_df.shape after drop: (1312, 16)\n",
            "# unique reports in curr_df: 1312 >= 1000\n",
            "total number of reports: 267759\n",
            "counter = 562 with 562000 documents elapsed\n",
            "counter = 563 with 563000 documents elapsed\n",
            "curr_df.shape after drop: (1282, 16)\n",
            "# unique reports in curr_df: 1282 >= 1000\n",
            "total number of reports: 269041\n",
            "counter = 564 with 564000 documents elapsed\n",
            "counter = 565 with 565000 documents elapsed\n",
            "curr_df.shape after drop: (1190, 16)\n",
            "# unique reports in curr_df: 1190 >= 1000\n",
            "total number of reports: 270231\n",
            "counter = 566 with 566000 documents elapsed\n",
            "counter = 567 with 567000 documents elapsed\n",
            "curr_df.shape after drop: (1243, 16)\n",
            "# unique reports in curr_df: 1243 >= 1000\n",
            "total number of reports: 271474\n",
            "counter = 568 with 568000 documents elapsed\n",
            "counter = 569 with 569000 documents elapsed\n",
            "curr_df.shape after drop: (1234, 16)\n",
            "# unique reports in curr_df: 1234 >= 1000\n",
            "total number of reports: 272708\n",
            "counter = 570 with 570000 documents elapsed\n",
            "counter = 571 with 571000 documents elapsed\n",
            "curr_df.shape after drop: (1194, 16)\n",
            "# unique reports in curr_df: 1194 >= 1000\n",
            "total number of reports: 273902\n",
            "counter = 572 with 572000 documents elapsed\n",
            "counter = 573 with 573000 documents elapsed\n",
            "curr_df.shape after drop: (1298, 16)\n",
            "# unique reports in curr_df: 1298 >= 1000\n",
            "total number of reports: 275200\n",
            "counter = 574 with 574000 documents elapsed\n",
            "counter = 575 with 575000 documents elapsed\n",
            "curr_df.shape after drop: (1291, 16)\n",
            "# unique reports in curr_df: 1291 >= 1000\n",
            "total number of reports: 276491\n",
            "counter = 576 with 576000 documents elapsed\n",
            "counter = 576 with 576000 documents elapsed\n",
            "counter = 577 with 577000 documents elapsed\n",
            "curr_df.shape after drop: (1251, 16)\n",
            "# unique reports in curr_df: 1251 >= 1000\n",
            "total number of reports: 277742\n",
            "counter = 578 with 578000 documents elapsed\n",
            "counter = 579 with 579000 documents elapsed\n",
            "curr_df.shape after drop: (1218, 16)\n",
            "# unique reports in curr_df: 1218 >= 1000\n",
            "total number of reports: 278960\n",
            "counter = 580 with 580000 documents elapsed\n",
            "counter = 581 with 581000 documents elapsed\n",
            "curr_df.shape after drop: (1158, 16)\n",
            "# unique reports in curr_df: 1158 >= 1000\n",
            "total number of reports: 280118\n",
            "counter = 582 with 582000 documents elapsed\n",
            "counter = 583 with 583000 documents elapsed\n",
            "curr_df.shape after drop: (1270, 16)\n",
            "# unique reports in curr_df: 1270 >= 1000\n",
            "total number of reports: 281388\n",
            "counter = 584 with 584000 documents elapsed\n",
            "counter = 585 with 585000 documents elapsed\n",
            "curr_df.shape after drop: (1256, 16)\n",
            "# unique reports in curr_df: 1256 >= 1000\n",
            "total number of reports: 282644\n",
            "counter = 586 with 586000 documents elapsed\n",
            "counter = 587 with 587000 documents elapsed\n",
            "curr_df.shape after drop: (1325, 16)\n",
            "# unique reports in curr_df: 1325 >= 1000\n",
            "total number of reports: 283969\n",
            "counter = 588 with 588000 documents elapsed\n",
            "counter = 589 with 589000 documents elapsed\n",
            "curr_df.shape after drop: (1278, 16)\n",
            "# unique reports in curr_df: 1278 >= 1000\n",
            "total number of reports: 285247\n",
            "counter = 590 with 590000 documents elapsed\n",
            "counter = 591 with 591000 documents elapsed\n",
            "curr_df.shape after drop: (1285, 16)\n",
            "# unique reports in curr_df: 1285 >= 1000\n",
            "total number of reports: 286532\n",
            "counter = 592 with 592000 documents elapsed\n",
            "counter = 593 with 593000 documents elapsed\n",
            "curr_df.shape after drop: (1291, 16)\n",
            "# unique reports in curr_df: 1291 >= 1000\n",
            "total number of reports: 287823\n",
            "counter = 594 with 594000 documents elapsed\n",
            "counter = 595 with 595000 documents elapsed\n",
            "curr_df.shape after drop: (1285, 16)\n",
            "# unique reports in curr_df: 1285 >= 1000\n",
            "total number of reports: 289108\n",
            "counter = 596 with 596000 documents elapsed\n",
            "counter = 596 with 596000 documents elapsed\n",
            "counter = 597 with 597000 documents elapsed\n",
            "curr_df.shape after drop: (1297, 16)\n",
            "# unique reports in curr_df: 1297 >= 1000\n",
            "total number of reports: 290405\n",
            "counter = 598 with 598000 documents elapsed\n",
            "counter = 599 with 599000 documents elapsed\n",
            "curr_df.shape after drop: (1241, 16)\n",
            "# unique reports in curr_df: 1241 >= 1000\n",
            "total number of reports: 291646\n",
            "counter = 600 with 600000 documents elapsed\n",
            "counter = 601 with 601000 documents elapsed\n",
            "curr_df.shape after drop: (1286, 16)\n",
            "# unique reports in curr_df: 1286 >= 1000\n",
            "total number of reports: 292932\n",
            "counter = 602 with 602000 documents elapsed\n",
            "counter = 603 with 603000 documents elapsed\n",
            "curr_df.shape after drop: (1280, 16)\n",
            "# unique reports in curr_df: 1280 >= 1000\n",
            "total number of reports: 294212\n",
            "counter = 604 with 604000 documents elapsed\n",
            "counter = 605 with 605000 documents elapsed\n",
            "counter = 605 with 605000 documents elapsed\n",
            "curr_df.shape after drop: (1259, 16)\n",
            "# unique reports in curr_df: 1259 >= 1000\n",
            "total number of reports: 295471\n",
            "counter = 606 with 606000 documents elapsed\n",
            "counter = 607 with 607000 documents elapsed\n",
            "curr_df.shape after drop: (1204, 16)\n",
            "# unique reports in curr_df: 1204 >= 1000\n",
            "total number of reports: 296675\n",
            "counter = 608 with 608000 documents elapsed\n",
            "counter = 609 with 609000 documents elapsed\n",
            "curr_df.shape after drop: (1265, 16)\n",
            "# unique reports in curr_df: 1265 >= 1000\n",
            "total number of reports: 297940\n",
            "counter = 610 with 610000 documents elapsed\n",
            "counter = 611 with 611000 documents elapsed\n",
            "curr_df.shape after drop: (1347, 16)\n",
            "# unique reports in curr_df: 1347 >= 1000\n",
            "total number of reports: 299287\n",
            "counter = 612 with 612000 documents elapsed\n",
            "counter = 613 with 613000 documents elapsed\n",
            "curr_df.shape after drop: (1326, 16)\n",
            "# unique reports in curr_df: 1326 >= 1000\n",
            "total number of reports: 300613\n",
            "counter = 614 with 614000 documents elapsed\n",
            "counter = 615 with 615000 documents elapsed\n",
            "curr_df.shape after drop: (1342, 16)\n",
            "# unique reports in curr_df: 1342 >= 1000\n",
            "total number of reports: 301955\n",
            "counter = 616 with 616000 documents elapsed\n",
            "counter = 617 with 617000 documents elapsed\n",
            "curr_df.shape after drop: (1295, 16)\n",
            "# unique reports in curr_df: 1295 >= 1000\n",
            "total number of reports: 303250\n",
            "counter = 618 with 618000 documents elapsed\n",
            "counter = 619 with 619000 documents elapsed\n",
            "curr_df.shape after drop: (1268, 16)\n",
            "# unique reports in curr_df: 1268 >= 1000\n",
            "total number of reports: 304518\n",
            "counter = 620 with 620000 documents elapsed\n",
            "counter = 621 with 621000 documents elapsed\n",
            "curr_df.shape after drop: (1253, 16)\n",
            "# unique reports in curr_df: 1253 >= 1000\n",
            "total number of reports: 305771\n",
            "counter = 622 with 622000 documents elapsed\n",
            "counter = 623 with 623000 documents elapsed\n",
            "curr_df.shape after drop: (1313, 16)\n",
            "# unique reports in curr_df: 1313 >= 1000\n",
            "total number of reports: 307084\n",
            "counter = 624 with 624000 documents elapsed\n",
            "counter = 625 with 625000 documents elapsed\n",
            "curr_df.shape after drop: (1215, 16)\n",
            "# unique reports in curr_df: 1215 >= 1000\n",
            "total number of reports: 308299\n",
            "counter = 626 with 626000 documents elapsed\n",
            "counter = 627 with 627000 documents elapsed\n",
            "curr_df.shape after drop: (1322, 16)\n",
            "# unique reports in curr_df: 1322 >= 1000\n",
            "total number of reports: 309621\n",
            "counter = 628 with 628000 documents elapsed\n",
            "counter = 629 with 629000 documents elapsed\n",
            "curr_df.shape after drop: (1339, 16)\n",
            "# unique reports in curr_df: 1339 >= 1000\n",
            "total number of reports: 310960\n",
            "counter = 630 with 630000 documents elapsed\n",
            "counter = 631 with 631000 documents elapsed\n",
            "curr_df.shape after drop: (1348, 16)\n",
            "# unique reports in curr_df: 1348 >= 1000\n",
            "total number of reports: 312308\n",
            "counter = 632 with 632000 documents elapsed\n",
            "counter = 633 with 633000 documents elapsed\n",
            "curr_df.shape after drop: (1345, 16)\n",
            "# unique reports in curr_df: 1345 >= 1000\n",
            "total number of reports: 313653\n",
            "counter = 634 with 634000 documents elapsed\n",
            "counter = 635 with 635000 documents elapsed\n",
            "curr_df.shape after drop: (1324, 16)\n",
            "# unique reports in curr_df: 1324 >= 1000\n",
            "total number of reports: 314977\n",
            "counter = 636 with 636000 documents elapsed\n",
            "counter = 637 with 637000 documents elapsed\n",
            "curr_df.shape after drop: (1278, 16)\n",
            "# unique reports in curr_df: 1278 >= 1000\n",
            "total number of reports: 316255\n",
            "counter = 638 with 638000 documents elapsed\n",
            "counter = 639 with 639000 documents elapsed\n",
            "curr_df.shape after drop: (1297, 16)\n",
            "# unique reports in curr_df: 1297 >= 1000\n",
            "total number of reports: 317552\n",
            "counter = 640 with 640000 documents elapsed\n",
            "counter = 641 with 641000 documents elapsed\n",
            "curr_df.shape after drop: (1309, 16)\n",
            "# unique reports in curr_df: 1309 >= 1000\n",
            "total number of reports: 318861\n",
            "counter = 642 with 642000 documents elapsed\n",
            "counter = 643 with 643000 documents elapsed\n",
            "curr_df.shape after drop: (1274, 16)\n",
            "# unique reports in curr_df: 1274 >= 1000\n",
            "total number of reports: 320135\n",
            "counter = 644 with 644000 documents elapsed\n",
            "counter = 645 with 645000 documents elapsed\n",
            "curr_df.shape after drop: (1255, 16)\n",
            "# unique reports in curr_df: 1255 >= 1000\n",
            "total number of reports: 321390\n",
            "counter = 646 with 646000 documents elapsed\n",
            "counter = 647 with 647000 documents elapsed\n",
            "curr_df.shape after drop: (1288, 16)\n",
            "# unique reports in curr_df: 1288 >= 1000\n",
            "total number of reports: 322678\n",
            "counter = 648 with 648000 documents elapsed\n",
            "counter = 649 with 649000 documents elapsed\n",
            "curr_df.shape after drop: (1276, 16)\n",
            "# unique reports in curr_df: 1276 >= 1000\n",
            "total number of reports: 323954\n",
            "counter = 650 with 650000 documents elapsed\n",
            "counter = 651 with 651000 documents elapsed\n",
            "curr_df.shape after drop: (1308, 16)\n",
            "# unique reports in curr_df: 1308 >= 1000\n",
            "total number of reports: 325262\n",
            "counter = 652 with 652000 documents elapsed\n",
            "counter = 653 with 653000 documents elapsed\n",
            "curr_df.shape after drop: (1263, 16)\n",
            "# unique reports in curr_df: 1263 >= 1000\n",
            "total number of reports: 326525\n",
            "counter = 654 with 654000 documents elapsed\n",
            "counter = 655 with 655000 documents elapsed\n",
            "curr_df.shape after drop: (1260, 16)\n",
            "# unique reports in curr_df: 1260 >= 1000\n",
            "total number of reports: 327785\n",
            "counter = 656 with 656000 documents elapsed\n",
            "counter = 657 with 657000 documents elapsed\n",
            "curr_df.shape after drop: (1206, 16)\n",
            "# unique reports in curr_df: 1206 >= 1000\n",
            "total number of reports: 328991\n",
            "counter = 658 with 658000 documents elapsed\n",
            "counter = 659 with 659000 documents elapsed\n",
            "curr_df.shape after drop: (1279, 16)\n",
            "# unique reports in curr_df: 1279 >= 1000\n",
            "total number of reports: 330270\n",
            "counter = 660 with 660000 documents elapsed\n",
            "counter = 661 with 661000 documents elapsed\n",
            "curr_df.shape after drop: (1324, 16)\n",
            "# unique reports in curr_df: 1324 >= 1000\n",
            "total number of reports: 331594\n",
            "counter = 662 with 662000 documents elapsed\n",
            "counter = 663 with 663000 documents elapsed\n",
            "curr_df.shape after drop: (1287, 16)\n",
            "# unique reports in curr_df: 1287 >= 1000\n",
            "total number of reports: 332881\n",
            "counter = 664 with 664000 documents elapsed\n",
            "counter = 665 with 665000 documents elapsed\n",
            "curr_df.shape after drop: (1187, 16)\n",
            "# unique reports in curr_df: 1187 >= 1000\n",
            "total number of reports: 334068\n",
            "counter = 666 with 666000 documents elapsed\n",
            "counter = 667 with 667000 documents elapsed\n",
            "curr_df.shape after drop: (1164, 16)\n",
            "# unique reports in curr_df: 1164 >= 1000\n",
            "total number of reports: 335232\n",
            "counter = 668 with 668000 documents elapsed\n",
            "counter = 669 with 669000 documents elapsed\n",
            "curr_df.shape after drop: (1251, 16)\n",
            "# unique reports in curr_df: 1251 >= 1000\n",
            "total number of reports: 336483\n",
            "counter = 670 with 670000 documents elapsed\n",
            "counter = 671 with 671000 documents elapsed\n",
            "curr_df.shape after drop: (1289, 16)\n",
            "# unique reports in curr_df: 1289 >= 1000\n",
            "total number of reports: 337772\n",
            "counter = 672 with 672000 documents elapsed\n",
            "counter = 673 with 673000 documents elapsed\n",
            "curr_df.shape after drop: (1349, 16)\n",
            "# unique reports in curr_df: 1349 >= 1000\n",
            "total number of reports: 339121\n",
            "counter = 674 with 674000 documents elapsed\n",
            "counter = 675 with 675000 documents elapsed\n",
            "curr_df.shape after drop: (1303, 16)\n",
            "# unique reports in curr_df: 1303 >= 1000\n",
            "total number of reports: 340424\n",
            "counter = 676 with 676000 documents elapsed\n",
            "counter = 677 with 677000 documents elapsed\n",
            "curr_df.shape after drop: (1333, 16)\n",
            "# unique reports in curr_df: 1333 >= 1000\n",
            "total number of reports: 341757\n",
            "counter = 678 with 678000 documents elapsed\n",
            "counter = 679 with 679000 documents elapsed\n",
            "curr_df.shape after drop: (1154, 16)\n",
            "# unique reports in curr_df: 1154 >= 1000\n",
            "total number of reports: 342911\n",
            "counter = 680 with 680000 documents elapsed\n",
            "counter = 681 with 681000 documents elapsed\n",
            "curr_df.shape after drop: (1221, 16)\n",
            "# unique reports in curr_df: 1221 >= 1000\n",
            "total number of reports: 344132\n",
            "counter = 682 with 682000 documents elapsed\n",
            "counter = 683 with 683000 documents elapsed\n",
            "curr_df.shape after drop: (1259, 16)\n",
            "# unique reports in curr_df: 1259 >= 1000\n",
            "total number of reports: 345391\n",
            "counter = 684 with 684000 documents elapsed\n",
            "counter = 685 with 685000 documents elapsed\n",
            "curr_df.shape after drop: (1220, 16)\n",
            "# unique reports in curr_df: 1220 >= 1000\n",
            "total number of reports: 346611\n",
            "counter = 686 with 686000 documents elapsed\n",
            "counter = 687 with 687000 documents elapsed\n",
            "curr_df.shape after drop: (1241, 16)\n",
            "# unique reports in curr_df: 1241 >= 1000\n",
            "total number of reports: 347852\n",
            "counter = 688 with 688000 documents elapsed\n",
            "counter = 689 with 689000 documents elapsed\n",
            "curr_df.shape after drop: (1282, 16)\n",
            "# unique reports in curr_df: 1282 >= 1000\n",
            "total number of reports: 349134\n",
            "counter = 690 with 690000 documents elapsed\n",
            "counter = 691 with 691000 documents elapsed\n",
            "curr_df.shape after drop: (1236, 16)\n",
            "# unique reports in curr_df: 1236 >= 1000\n",
            "total number of reports: 350370\n",
            "counter = 692 with 692000 documents elapsed\n",
            "counter = 693 with 693000 documents elapsed\n",
            "curr_df.shape after drop: (1301, 16)\n",
            "# unique reports in curr_df: 1301 >= 1000\n",
            "total number of reports: 351671\n",
            "counter = 694 with 694000 documents elapsed\n",
            "counter = 695 with 695000 documents elapsed\n",
            "curr_df.shape after drop: (1248, 16)\n",
            "# unique reports in curr_df: 1248 >= 1000\n",
            "total number of reports: 352919\n",
            "counter = 696 with 696000 documents elapsed\n",
            "counter = 697 with 697000 documents elapsed\n",
            "curr_df.shape after drop: (1290, 16)\n",
            "# unique reports in curr_df: 1290 >= 1000\n",
            "total number of reports: 354209\n",
            "counter = 698 with 698000 documents elapsed\n",
            "counter = 699 with 699000 documents elapsed\n",
            "curr_df.shape after drop: (1307, 16)\n",
            "# unique reports in curr_df: 1307 >= 1000\n",
            "total number of reports: 355516\n",
            "counter = 700 with 700000 documents elapsed\n",
            "counter = 701 with 701000 documents elapsed\n",
            "curr_df.shape after drop: (1273, 16)\n",
            "# unique reports in curr_df: 1273 >= 1000\n",
            "total number of reports: 356789\n",
            "counter = 702 with 702000 documents elapsed\n",
            "counter = 703 with 703000 documents elapsed\n",
            "curr_df.shape after drop: (1231, 16)\n",
            "# unique reports in curr_df: 1231 >= 1000\n",
            "total number of reports: 358020\n",
            "counter = 704 with 704000 documents elapsed\n",
            "counter = 705 with 705000 documents elapsed\n",
            "curr_df.shape after drop: (1238, 16)\n",
            "# unique reports in curr_df: 1238 >= 1000\n",
            "total number of reports: 359258\n",
            "counter = 706 with 706000 documents elapsed\n",
            "counter = 707 with 707000 documents elapsed\n",
            "curr_df.shape after drop: (1208, 16)\n",
            "# unique reports in curr_df: 1208 >= 1000\n",
            "total number of reports: 360466\n",
            "counter = 708 with 708000 documents elapsed\n",
            "counter = 709 with 709000 documents elapsed\n",
            "curr_df.shape after drop: (1332, 16)\n",
            "# unique reports in curr_df: 1332 >= 1000\n",
            "total number of reports: 361798\n",
            "counter = 710 with 710000 documents elapsed\n",
            "counter = 711 with 711000 documents elapsed\n",
            "curr_df.shape after drop: (1244, 16)\n",
            "# unique reports in curr_df: 1244 >= 1000\n",
            "total number of reports: 363042\n",
            "counter = 712 with 712000 documents elapsed\n",
            "counter = 713 with 713000 documents elapsed\n",
            "curr_df.shape after drop: (1242, 16)\n",
            "# unique reports in curr_df: 1242 >= 1000\n",
            "total number of reports: 364284\n",
            "counter = 714 with 714000 documents elapsed\n",
            "counter = 715 with 715000 documents elapsed\n",
            "curr_df.shape after drop: (1172, 16)\n",
            "# unique reports in curr_df: 1172 >= 1000\n",
            "total number of reports: 365456\n",
            "counter = 716 with 716000 documents elapsed\n",
            "counter = 717 with 717000 documents elapsed\n",
            "curr_df.shape after drop: (1328, 16)\n",
            "# unique reports in curr_df: 1328 >= 1000\n",
            "total number of reports: 366784\n",
            "counter = 718 with 718000 documents elapsed\n",
            "counter = 719 with 719000 documents elapsed\n",
            "curr_df.shape after drop: (1244, 16)\n",
            "# unique reports in curr_df: 1244 >= 1000\n",
            "total number of reports: 368028\n",
            "counter = 720 with 720000 documents elapsed\n",
            "counter = 721 with 721000 documents elapsed\n",
            "curr_df.shape after drop: (1239, 16)\n",
            "# unique reports in curr_df: 1239 >= 1000\n",
            "total number of reports: 369267\n",
            "counter = 722 with 722000 documents elapsed\n",
            "counter = 723 with 723000 documents elapsed\n",
            "curr_df.shape after drop: (1291, 16)\n",
            "# unique reports in curr_df: 1291 >= 1000\n",
            "total number of reports: 370558\n",
            "counter = 724 with 724000 documents elapsed\n",
            "counter = 725 with 725000 documents elapsed\n",
            "curr_df.shape after drop: (1198, 16)\n",
            "# unique reports in curr_df: 1198 >= 1000\n",
            "total number of reports: 371756\n",
            "counter = 726 with 726000 documents elapsed\n",
            "counter = 727 with 727000 documents elapsed\n",
            "curr_df.shape after drop: (1314, 16)\n",
            "# unique reports in curr_df: 1314 >= 1000\n",
            "total number of reports: 373070\n",
            "counter = 728 with 728000 documents elapsed\n",
            "counter = 729 with 729000 documents elapsed\n",
            "curr_df.shape after drop: (1247, 16)\n",
            "# unique reports in curr_df: 1247 >= 1000\n",
            "total number of reports: 374317\n",
            "counter = 730 with 730000 documents elapsed\n",
            "counter = 731 with 731000 documents elapsed\n",
            "curr_df.shape after drop: (1296, 16)\n",
            "# unique reports in curr_df: 1296 >= 1000\n",
            "total number of reports: 375613\n",
            "counter = 732 with 732000 documents elapsed\n",
            "counter = 733 with 733000 documents elapsed\n",
            "curr_df.shape after drop: (1287, 16)\n",
            "# unique reports in curr_df: 1287 >= 1000\n",
            "total number of reports: 376900\n",
            "counter = 734 with 734000 documents elapsed\n",
            "counter = 735 with 735000 documents elapsed\n",
            "curr_df.shape after drop: (1270, 16)\n",
            "# unique reports in curr_df: 1270 >= 1000\n",
            "total number of reports: 378170\n",
            "counter = 736 with 736000 documents elapsed\n",
            "counter = 737 with 737000 documents elapsed\n",
            "curr_df.shape after drop: (1280, 16)\n",
            "# unique reports in curr_df: 1280 >= 1000\n",
            "total number of reports: 379450\n",
            "counter = 738 with 738000 documents elapsed\n",
            "counter = 739 with 739000 documents elapsed\n",
            "curr_df.shape after drop: (1212, 16)\n",
            "# unique reports in curr_df: 1212 >= 1000\n",
            "total number of reports: 380662\n",
            "counter = 740 with 740000 documents elapsed\n",
            "counter = 741 with 741000 documents elapsed\n",
            "curr_df.shape after drop: (1215, 16)\n",
            "# unique reports in curr_df: 1215 >= 1000\n",
            "total number of reports: 381877\n",
            "counter = 742 with 742000 documents elapsed\n",
            "counter = 743 with 743000 documents elapsed\n",
            "curr_df.shape after drop: (1281, 16)\n",
            "# unique reports in curr_df: 1281 >= 1000\n",
            "total number of reports: 383158\n",
            "counter = 744 with 744000 documents elapsed\n",
            "counter = 745 with 745000 documents elapsed\n",
            "curr_df.shape after drop: (1209, 16)\n",
            "# unique reports in curr_df: 1209 >= 1000\n",
            "total number of reports: 384367\n",
            "counter = 746 with 746000 documents elapsed\n",
            "counter = 747 with 747000 documents elapsed\n",
            "curr_df.shape after drop: (1160, 16)\n",
            "# unique reports in curr_df: 1160 >= 1000\n",
            "total number of reports: 385527\n",
            "counter = 748 with 748000 documents elapsed\n",
            "counter = 749 with 749000 documents elapsed\n",
            "curr_df.shape after drop: (1246, 16)\n",
            "# unique reports in curr_df: 1246 >= 1000\n",
            "total number of reports: 386773\n",
            "counter = 750 with 750000 documents elapsed\n",
            "counter = 751 with 751000 documents elapsed\n",
            "curr_df.shape after drop: (1226, 16)\n",
            "# unique reports in curr_df: 1226 >= 1000\n",
            "total number of reports: 387999\n",
            "counter = 752 with 752000 documents elapsed\n",
            "counter = 753 with 753000 documents elapsed\n",
            "curr_df.shape after drop: (1094, 16)\n",
            "# unique reports in curr_df: 1094 >= 1000\n",
            "total number of reports: 389093\n",
            "counter = 754 with 754000 documents elapsed\n",
            "counter = 755 with 755000 documents elapsed\n",
            "curr_df.shape after drop: (1125, 16)\n",
            "# unique reports in curr_df: 1125 >= 1000\n",
            "total number of reports: 390218\n",
            "counter = 756 with 756000 documents elapsed\n",
            "counter = 757 with 757000 documents elapsed\n",
            "curr_df.shape after drop: (1191, 16)\n",
            "# unique reports in curr_df: 1191 >= 1000\n",
            "total number of reports: 391409\n",
            "counter = 758 with 758000 documents elapsed\n",
            "counter = 759 with 759000 documents elapsed\n",
            "curr_df.shape after drop: (1232, 16)\n",
            "# unique reports in curr_df: 1232 >= 1000\n",
            "total number of reports: 392641\n",
            "counter = 760 with 760000 documents elapsed\n",
            "counter = 761 with 761000 documents elapsed\n",
            "curr_df.shape after drop: (1241, 16)\n",
            "# unique reports in curr_df: 1241 >= 1000\n",
            "total number of reports: 393882\n",
            "counter = 762 with 762000 documents elapsed\n",
            "counter = 763 with 763000 documents elapsed\n",
            "curr_df.shape after drop: (1129, 16)\n",
            "# unique reports in curr_df: 1129 >= 1000\n",
            "total number of reports: 395011\n",
            "counter = 764 with 764000 documents elapsed\n",
            "counter = 765 with 765000 documents elapsed\n",
            "curr_df.shape after drop: (1377, 16)\n",
            "# unique reports in curr_df: 1377 >= 1000\n",
            "total number of reports: 396388\n",
            "counter = 766 with 766000 documents elapsed\n",
            "counter = 767 with 767000 documents elapsed\n",
            "curr_df.shape after drop: (1282, 16)\n",
            "# unique reports in curr_df: 1282 >= 1000\n",
            "total number of reports: 397670\n",
            "counter = 768 with 768000 documents elapsed\n",
            "counter = 769 with 769000 documents elapsed\n",
            "curr_df.shape after drop: (1429, 16)\n",
            "# unique reports in curr_df: 1429 >= 1000\n",
            "total number of reports: 399099\n",
            "counter = 770 with 770000 documents elapsed\n",
            "counter = 771 with 771000 documents elapsed\n",
            "curr_df.shape after drop: (1362, 16)\n",
            "# unique reports in curr_df: 1362 >= 1000\n",
            "total number of reports: 400461\n",
            "counter = 772 with 772000 documents elapsed\n",
            "counter = 773 with 773000 documents elapsed\n",
            "curr_df.shape after drop: (1306, 16)\n",
            "# unique reports in curr_df: 1306 >= 1000\n",
            "total number of reports: 401767\n",
            "counter = 774 with 774000 documents elapsed\n",
            "counter = 775 with 775000 documents elapsed\n",
            "curr_df.shape after drop: (1151, 16)\n",
            "# unique reports in curr_df: 1151 >= 1000\n",
            "total number of reports: 402918\n",
            "counter = 776 with 776000 documents elapsed\n",
            "counter = 777 with 777000 documents elapsed\n",
            "curr_df.shape after drop: (1256, 16)\n",
            "# unique reports in curr_df: 1256 >= 1000\n",
            "total number of reports: 404174\n",
            "counter = 778 with 778000 documents elapsed\n",
            "counter = 778 with 778000 documents elapsed\n",
            "counter = 779 with 779000 documents elapsed\n",
            "curr_df.shape after drop: (1265, 16)\n",
            "# unique reports in curr_df: 1265 >= 1000\n",
            "total number of reports: 405439\n",
            "counter = 780 with 780000 documents elapsed\n",
            "counter = 781 with 781000 documents elapsed\n",
            "curr_df.shape after drop: (1157, 16)\n",
            "# unique reports in curr_df: 1157 >= 1000\n",
            "total number of reports: 406596\n",
            "counter = 782 with 782000 documents elapsed\n",
            "counter = 783 with 783000 documents elapsed\n",
            "curr_df.shape after drop: (1254, 16)\n",
            "# unique reports in curr_df: 1254 >= 1000\n",
            "total number of reports: 407850\n",
            "counter = 784 with 784000 documents elapsed\n",
            "counter = 785 with 785000 documents elapsed\n",
            "curr_df.shape after drop: (1125, 16)\n",
            "# unique reports in curr_df: 1125 >= 1000\n",
            "total number of reports: 408975\n",
            "counter = 786 with 786000 documents elapsed\n",
            "counter = 787 with 787000 documents elapsed\n",
            "curr_df.shape after drop: (1244, 16)\n",
            "# unique reports in curr_df: 1244 >= 1000\n",
            "total number of reports: 410219\n",
            "counter = 788 with 788000 documents elapsed\n",
            "counter = 789 with 789000 documents elapsed\n",
            "curr_df.shape after drop: (1218, 16)\n",
            "# unique reports in curr_df: 1218 >= 1000\n",
            "total number of reports: 411437\n",
            "counter = 790 with 790000 documents elapsed\n",
            "counter = 791 with 791000 documents elapsed\n",
            "curr_df.shape after drop: (1190, 16)\n",
            "# unique reports in curr_df: 1190 >= 1000\n",
            "total number of reports: 412627\n",
            "counter = 792 with 792000 documents elapsed\n",
            "counter = 793 with 793000 documents elapsed\n",
            "curr_df.shape after drop: (1262, 16)\n",
            "# unique reports in curr_df: 1262 >= 1000\n",
            "total number of reports: 413889\n",
            "counter = 794 with 794000 documents elapsed\n",
            "counter = 795 with 795000 documents elapsed\n",
            "curr_df.shape after drop: (1102, 16)\n",
            "# unique reports in curr_df: 1102 >= 1000\n",
            "total number of reports: 414991\n",
            "counter = 796 with 796000 documents elapsed\n",
            "counter = 797 with 797000 documents elapsed\n",
            "curr_df.shape after drop: (1219, 16)\n",
            "# unique reports in curr_df: 1219 >= 1000\n",
            "total number of reports: 416210\n",
            "counter = 798 with 798000 documents elapsed\n",
            "counter = 799 with 799000 documents elapsed\n",
            "curr_df.shape after drop: (1066, 16)\n",
            "# unique reports in curr_df: 1066 >= 1000\n",
            "total number of reports: 417276\n",
            "counter = 800 with 800000 documents elapsed\n",
            "counter = 801 with 801000 documents elapsed\n",
            "curr_df.shape after drop: (1258, 16)\n",
            "# unique reports in curr_df: 1258 >= 1000\n",
            "total number of reports: 418534\n",
            "counter = 802 with 802000 documents elapsed\n",
            "counter = 803 with 803000 documents elapsed\n",
            "curr_df.shape after drop: (1216, 16)\n",
            "# unique reports in curr_df: 1216 >= 1000\n",
            "total number of reports: 419750\n",
            "counter = 804 with 804000 documents elapsed\n",
            "counter = 805 with 805000 documents elapsed\n",
            "curr_df.shape after drop: (1321, 16)\n",
            "# unique reports in curr_df: 1321 >= 1000\n",
            "total number of reports: 421071\n",
            "counter = 806 with 806000 documents elapsed\n",
            "counter = 807 with 807000 documents elapsed\n",
            "curr_df.shape after drop: (1190, 16)\n",
            "# unique reports in curr_df: 1190 >= 1000\n",
            "total number of reports: 422261\n",
            "counter = 808 with 808000 documents elapsed\n",
            "counter = 809 with 809000 documents elapsed\n",
            "curr_df.shape after drop: (1367, 16)\n",
            "# unique reports in curr_df: 1367 >= 1000\n",
            "total number of reports: 423628\n",
            "counter = 810 with 810000 documents elapsed\n",
            "counter = 811 with 811000 documents elapsed\n",
            "curr_df.shape after drop: (1298, 16)\n",
            "# unique reports in curr_df: 1298 >= 1000\n",
            "total number of reports: 424926\n",
            "counter = 812 with 812000 documents elapsed\n",
            "counter = 813 with 813000 documents elapsed\n",
            "curr_df.shape after drop: (1325, 16)\n",
            "# unique reports in curr_df: 1325 >= 1000\n",
            "total number of reports: 426251\n",
            "counter = 814 with 814000 documents elapsed\n",
            "counter = 815 with 815000 documents elapsed\n",
            "curr_df.shape after drop: (1259, 16)\n",
            "# unique reports in curr_df: 1259 >= 1000\n",
            "total number of reports: 427510\n",
            "counter = 816 with 816000 documents elapsed\n",
            "counter = 817 with 817000 documents elapsed\n",
            "curr_df.shape after drop: (1147, 16)\n",
            "# unique reports in curr_df: 1147 >= 1000\n",
            "total number of reports: 428657\n",
            "counter = 818 with 818000 documents elapsed\n",
            "counter = 819 with 819000 documents elapsed\n",
            "curr_df.shape after drop: (1330, 16)\n",
            "# unique reports in curr_df: 1330 >= 1000\n",
            "total number of reports: 429987\n",
            "counter = 820 with 820000 documents elapsed\n",
            "counter = 821 with 821000 documents elapsed\n",
            "curr_df.shape after drop: (1171, 16)\n",
            "# unique reports in curr_df: 1171 >= 1000\n",
            "total number of reports: 431158\n",
            "counter = 822 with 822000 documents elapsed\n",
            "counter = 823 with 823000 documents elapsed\n",
            "curr_df.shape after drop: (1284, 16)\n",
            "# unique reports in curr_df: 1284 >= 1000\n",
            "total number of reports: 432442\n",
            "counter = 824 with 824000 documents elapsed\n",
            "counter = 825 with 825000 documents elapsed\n",
            "curr_df.shape after drop: (1280, 16)\n",
            "# unique reports in curr_df: 1280 >= 1000\n",
            "total number of reports: 433722\n",
            "counter = 826 with 826000 documents elapsed\n",
            "counter = 827 with 827000 documents elapsed\n",
            "curr_df.shape after drop: (1231, 16)\n",
            "# unique reports in curr_df: 1231 >= 1000\n",
            "total number of reports: 434953\n",
            "counter = 828 with 828000 documents elapsed\n",
            "counter = 829 with 829000 documents elapsed\n",
            "curr_df.shape after drop: (1191, 16)\n",
            "# unique reports in curr_df: 1191 >= 1000\n",
            "total number of reports: 436144\n",
            "counter = 830 with 830000 documents elapsed\n",
            "counter = 831 with 831000 documents elapsed\n",
            "curr_df.shape after drop: (1330, 16)\n",
            "# unique reports in curr_df: 1330 >= 1000\n",
            "total number of reports: 437474\n",
            "counter = 832 with 832000 documents elapsed\n",
            "counter = 833 with 833000 documents elapsed\n",
            "curr_df.shape after drop: (1308, 16)\n",
            "# unique reports in curr_df: 1308 >= 1000\n",
            "total number of reports: 438782\n",
            "counter = 834 with 834000 documents elapsed\n",
            "counter = 835 with 835000 documents elapsed\n",
            "curr_df.shape after drop: (1202, 16)\n",
            "# unique reports in curr_df: 1202 >= 1000\n",
            "total number of reports: 439984\n",
            "counter = 836 with 836000 documents elapsed\n",
            "counter = 837 with 837000 documents elapsed\n",
            "curr_df.shape after drop: (1370, 16)\n",
            "# unique reports in curr_df: 1370 >= 1000\n",
            "total number of reports: 441354\n",
            "counter = 838 with 838000 documents elapsed\n",
            "counter = 839 with 839000 documents elapsed\n",
            "curr_df.shape after drop: (1322, 16)\n",
            "# unique reports in curr_df: 1322 >= 1000\n",
            "total number of reports: 442676\n",
            "counter = 840 with 840000 documents elapsed\n",
            "counter = 840 with 840000 documents elapsed\n",
            "counter = 841 with 841000 documents elapsed\n",
            "curr_df.shape after drop: (1365, 16)\n",
            "# unique reports in curr_df: 1365 >= 1000\n",
            "total number of reports: 444041\n",
            "counter = 842 with 842000 documents elapsed\n",
            "counter = 843 with 843000 documents elapsed\n",
            "curr_df.shape after drop: (1339, 16)\n",
            "# unique reports in curr_df: 1339 >= 1000\n",
            "total number of reports: 445380\n",
            "counter = 844 with 844000 documents elapsed\n",
            "counter = 845 with 845000 documents elapsed\n",
            "curr_df.shape after drop: (1283, 16)\n",
            "# unique reports in curr_df: 1283 >= 1000\n",
            "total number of reports: 446663\n",
            "counter = 846 with 846000 documents elapsed\n",
            "counter = 847 with 847000 documents elapsed\n",
            "curr_df.shape after drop: (1256, 16)\n",
            "# unique reports in curr_df: 1256 >= 1000\n",
            "total number of reports: 447919\n",
            "counter = 848 with 848000 documents elapsed\n",
            "counter = 849 with 849000 documents elapsed\n",
            "curr_df.shape after drop: (1364, 16)\n",
            "# unique reports in curr_df: 1364 >= 1000\n",
            "total number of reports: 449283\n",
            "counter = 850 with 850000 documents elapsed\n",
            "counter = 851 with 851000 documents elapsed\n",
            "curr_df.shape after drop: (1302, 16)\n",
            "# unique reports in curr_df: 1302 >= 1000\n",
            "total number of reports: 450585\n",
            "counter = 852 with 852000 documents elapsed\n",
            "counter = 853 with 853000 documents elapsed\n",
            "curr_df.shape after drop: (1340, 16)\n",
            "# unique reports in curr_df: 1340 >= 1000\n",
            "total number of reports: 451925\n",
            "counter = 854 with 854000 documents elapsed\n",
            "counter = 855 with 855000 documents elapsed\n",
            "curr_df.shape after drop: (1399, 16)\n",
            "# unique reports in curr_df: 1399 >= 1000\n",
            "total number of reports: 453324\n",
            "counter = 856 with 856000 documents elapsed\n",
            "counter = 857 with 857000 documents elapsed\n",
            "curr_df.shape after drop: (1284, 16)\n",
            "# unique reports in curr_df: 1284 >= 1000\n",
            "total number of reports: 454608\n",
            "counter = 858 with 858000 documents elapsed\n",
            "counter = 859 with 859000 documents elapsed\n",
            "curr_df.shape after drop: (1283, 16)\n",
            "# unique reports in curr_df: 1283 >= 1000\n",
            "total number of reports: 455891\n",
            "counter = 860 with 860000 documents elapsed\n",
            "counter = 861 with 861000 documents elapsed\n",
            "curr_df.shape after drop: (1352, 16)\n",
            "# unique reports in curr_df: 1352 >= 1000\n",
            "total number of reports: 457243\n",
            "counter = 862 with 862000 documents elapsed\n",
            "counter = 863 with 863000 documents elapsed\n",
            "curr_df.shape after drop: (1314, 16)\n",
            "# unique reports in curr_df: 1314 >= 1000\n",
            "total number of reports: 458557\n",
            "counter = 864 with 864000 documents elapsed\n",
            "counter = 865 with 865000 documents elapsed\n",
            "curr_df.shape after drop: (1380, 16)\n",
            "# unique reports in curr_df: 1380 >= 1000\n",
            "total number of reports: 459937\n",
            "counter = 866 with 866000 documents elapsed\n",
            "limit has been updated because reached last set of documents\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'next'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-94889c4edb2f>\u001b[0m in \u001b[0;36mextract_docs\u001b[0;34m(doc_limit, tot_docs)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m### GL 6/4: Extract themes as a single list into 1 row - based on Riddhisha's code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mtemp_theme_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'theme'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mtheme_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtheme\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtheme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_theme_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'theme'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-80074d888670>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_docs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#output = extract_docs(1000, 10030)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#print(f\"output.shape: {output.shape} with {len(output['report_id'].unique())} unique documents\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'number of unique documents: {output}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-94889c4edb2f>\u001b[0m in \u001b[0;36mextract_docs\u001b[0;34m(doc_limit, tot_docs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;31m#        print(f'Error (in report extraction) {e}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;31m# Update url for next API call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrw_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'links'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'next'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'next'"
          ]
        }
      ],
      "source": [
        "output = extract_docs(1000)\n",
        "#print(f\"output.shape: {output.shape} with {len(output['report_id'].unique())} unique documents\")\n",
        "print(f'number of unique documents: {output}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gOsi2e1Uz9n2",
        "outputId": "8d24e390-5e9b-41f6-d8eb-346365ef9e15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(459937, 16)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"report_id\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 10365,\n        \"max\": 10657,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          10419,\n          10657,\n          10453\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"theme_id\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"theme_name\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The MFEWS Central America Weather Hazards and Benefits Assessment For July 31 - August 6, 2008\",\n          \"Central America Weather Hazards Assessment: August 28 - September 3, 2008\",\n          \"The MFEWS Central America Weather Hazards and Benefits Assessment For August 7 - August 13, 2008\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Note: Document is two pages.\",\n          \"Note: Document is two pages\",\n          \"Note: document is two pages\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"combined_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The MFEWS Central America Weather Hazards and Benefits Assessment For July 31 - August 6, 2008 Note: Document is two pages.\",\n          \"Central America Weather Hazards Assessment: August 28 - September 3, 2008 Note: Document is two pages\",\n          \"The MFEWS Central America Weather Hazards and Benefits Assessment For August 7 - August 13, 2008 NOTE: Document is two pages.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"https://reliefweb.int/node/10419\",\n          \"https://reliefweb.int/node/10657\",\n          \"https://reliefweb.int/node/10453\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 17.22,\n        \"max\": 17.22,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          17.22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"longitude\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": -88.69,\n        \"max\": -88.69,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -88.69\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"country_iso3\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"blz\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"country_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Belize\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date_created\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2008-07-30T04:00:00+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"529\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Famine Early Warning System Network\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"format\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"News and Press Release\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"word_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.8809720581775866,\n        \"min\": 15.0,\n        \"max\": 21.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          21.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-f15110ae-14ed-4388-b766-4317f1c60682\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>report_id</th>\n",
              "      <th>theme_id</th>\n",
              "      <th>theme_name</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>combined_text</th>\n",
              "      <th>url</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>country_iso3</th>\n",
              "      <th>country_name</th>\n",
              "      <th>date_created</th>\n",
              "      <th>source_id</th>\n",
              "      <th>source_name</th>\n",
              "      <th>format</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10365</td>\n",
              "      <td>[4590]</td>\n",
              "      <td>[Coordination]</td>\n",
              "      <td>The MFEWS Central America Weather Hazards and ...</td>\n",
              "      <td>Note: document is two pages</td>\n",
              "      <td>The MFEWS Central America Weather Hazards and ...</td>\n",
              "      <td>https://reliefweb.int/node/10365</td>\n",
              "      <td>17.22</td>\n",
              "      <td>-88.69</td>\n",
              "      <td>blz</td>\n",
              "      <td>Belize</td>\n",
              "      <td>2008-07-23T04:00:00+00:00</td>\n",
              "      <td>529</td>\n",
              "      <td>Famine Early Warning System Network</td>\n",
              "      <td>News and Press Release</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10419</td>\n",
              "      <td>[4590]</td>\n",
              "      <td>[Coordination]</td>\n",
              "      <td>The MFEWS Central America Weather Hazards and ...</td>\n",
              "      <td>Note: Document is two pages.</td>\n",
              "      <td>The MFEWS Central America Weather Hazards and ...</td>\n",
              "      <td>https://reliefweb.int/node/10419</td>\n",
              "      <td>17.22</td>\n",
              "      <td>-88.69</td>\n",
              "      <td>blz</td>\n",
              "      <td>Belize</td>\n",
              "      <td>2008-07-30T04:00:00+00:00</td>\n",
              "      <td>529</td>\n",
              "      <td>Famine Early Warning System Network</td>\n",
              "      <td>News and Press Release</td>\n",
              "      <td>21.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10453</td>\n",
              "      <td>[4590]</td>\n",
              "      <td>[Coordination]</td>\n",
              "      <td>The MFEWS Central America Weather Hazards and ...</td>\n",
              "      <td>NOTE: Document is two pages.</td>\n",
              "      <td>The MFEWS Central America Weather Hazards and ...</td>\n",
              "      <td>https://reliefweb.int/node/10453</td>\n",
              "      <td>17.22</td>\n",
              "      <td>-88.69</td>\n",
              "      <td>blz</td>\n",
              "      <td>Belize</td>\n",
              "      <td>2008-08-06T04:00:00+00:00</td>\n",
              "      <td>529</td>\n",
              "      <td>Famine Early Warning System Network</td>\n",
              "      <td>News and Press Release</td>\n",
              "      <td>21.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10506</td>\n",
              "      <td>[4590]</td>\n",
              "      <td>[Coordination]</td>\n",
              "      <td>Central America Weather Hazards Assessment: Au...</td>\n",
              "      <td>Note: Document is two pages</td>\n",
              "      <td>Central America Weather Hazards Assessment: Au...</td>\n",
              "      <td>https://reliefweb.int/node/10506</td>\n",
              "      <td>17.22</td>\n",
              "      <td>-88.69</td>\n",
              "      <td>blz</td>\n",
              "      <td>Belize</td>\n",
              "      <td>2008-08-14T04:00:00+00:00</td>\n",
              "      <td>529</td>\n",
              "      <td>Famine Early Warning System Network</td>\n",
              "      <td>News and Press Release</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10657</td>\n",
              "      <td>[4590]</td>\n",
              "      <td>[Coordination]</td>\n",
              "      <td>Central America Weather Hazards Assessment: Au...</td>\n",
              "      <td>Note: Document is two pages</td>\n",
              "      <td>Central America Weather Hazards Assessment: Au...</td>\n",
              "      <td>https://reliefweb.int/node/10657</td>\n",
              "      <td>17.22</td>\n",
              "      <td>-88.69</td>\n",
              "      <td>blz</td>\n",
              "      <td>Belize</td>\n",
              "      <td>2008-08-28T04:00:00+00:00</td>\n",
              "      <td>529</td>\n",
              "      <td>Famine Early Warning System Network</td>\n",
              "      <td>News and Press Release</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f15110ae-14ed-4388-b766-4317f1c60682')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f15110ae-14ed-4388-b766-4317f1c60682 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f15110ae-14ed-4388-b766-4317f1c60682');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5cd2f678-2904-4066-97d1-373392259286\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5cd2f678-2904-4066-97d1-373392259286')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5cd2f678-2904-4066-97d1-373392259286 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  report_id theme_id      theme_name  \\\n",
              "0     10365   [4590]  [Coordination]   \n",
              "1     10419   [4590]  [Coordination]   \n",
              "2     10453   [4590]  [Coordination]   \n",
              "3     10506   [4590]  [Coordination]   \n",
              "4     10657   [4590]  [Coordination]   \n",
              "\n",
              "                                               title  \\\n",
              "0  The MFEWS Central America Weather Hazards and ...   \n",
              "1  The MFEWS Central America Weather Hazards and ...   \n",
              "2  The MFEWS Central America Weather Hazards and ...   \n",
              "3  Central America Weather Hazards Assessment: Au...   \n",
              "4  Central America Weather Hazards Assessment: Au...   \n",
              "\n",
              "                           text  \\\n",
              "0   Note: document is two pages   \n",
              "1  Note: Document is two pages.   \n",
              "2  NOTE: Document is two pages.   \n",
              "3   Note: Document is two pages   \n",
              "4   Note: Document is two pages   \n",
              "\n",
              "                                       combined_text  \\\n",
              "0  The MFEWS Central America Weather Hazards and ...   \n",
              "1  The MFEWS Central America Weather Hazards and ...   \n",
              "2  The MFEWS Central America Weather Hazards and ...   \n",
              "3  Central America Weather Hazards Assessment: Au...   \n",
              "4  Central America Weather Hazards Assessment: Au...   \n",
              "\n",
              "                                url  latitude  longitude country_iso3  \\\n",
              "0  https://reliefweb.int/node/10365     17.22     -88.69          blz   \n",
              "1  https://reliefweb.int/node/10419     17.22     -88.69          blz   \n",
              "2  https://reliefweb.int/node/10453     17.22     -88.69          blz   \n",
              "3  https://reliefweb.int/node/10506     17.22     -88.69          blz   \n",
              "4  https://reliefweb.int/node/10657     17.22     -88.69          blz   \n",
              "\n",
              "  country_name               date_created source_id  \\\n",
              "0       Belize  2008-07-23T04:00:00+00:00       529   \n",
              "1       Belize  2008-07-30T04:00:00+00:00       529   \n",
              "2       Belize  2008-08-06T04:00:00+00:00       529   \n",
              "3       Belize  2008-08-14T04:00:00+00:00       529   \n",
              "4       Belize  2008-08-28T04:00:00+00:00       529   \n",
              "\n",
              "                           source_name                  format  word_count  \n",
              "0  Famine Early Warning System Network  News and Press Release        20.0  \n",
              "1  Famine Early Warning System Network  News and Press Release        21.0  \n",
              "2  Famine Early Warning System Network  News and Press Release        21.0  \n",
              "3  Famine Early Warning System Network  News and Press Release        15.0  \n",
              "4  Famine Early Warning System Network  News and Press Release        16.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Function to read in all pickle files and concatenate to dataframe\n",
        "def read_pickles(base_path):\n",
        "  dir_list = os.listdir(base_path)\n",
        "  df = pd.DataFrame(columns = ['report_id', 'theme_id', 'theme_name', 'title', 'text', 'combined_text',\n",
        "                               'url', 'latitude', 'longitude', 'country_iso3','country_name',\n",
        "                               'date_created', 'source_id', 'source_name', 'format', 'word_count'])\n",
        "\n",
        "  for filename in dir_list:\n",
        "    path = f'{base_path}/{filename}'\n",
        "    df_new = pd.read_pickle(path)\n",
        "    # Update df\n",
        "    df= pd.concat([df, df_new])\n",
        "  return df\n",
        "\n",
        "df = read_pickles(base_path+'gl_files_v2/')\n",
        "print(df.shape)\n",
        "display(df.head())\n",
        "\n",
        "# Save full data frame to pickle file\n",
        "df.to_pickle(base_path + 'gl_full_pickle.pickle')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}